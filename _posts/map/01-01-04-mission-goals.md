---
date: 01-01-04
title: MAP 1.4
categories:
  - MAP-1
description: The organization’s mission and relevant goals for the AI technology are understood.
type: Map
order_number: 4
---

{::options parse_block_html="true" /}

<details>
<summary markdown="span">**What is this subcategory about?**</summary>
<br>
Socio-technical AI risks emerge from the interplay between technical development decisions and how a system is used, who operates it, and the social context into which it is deployed. Addressing these risks is complex and requires a commitment to understanding how contextual factors may interact with AI lifecycle actions. One such contextual factor is how organizational mission and identified system purpose create incentives within AI system design, development, and deployment tasks that may result in positive and negative impacts. By establishing comprehensive and explicit enumeration of AI system purpose and expectations, organizations can identify and manage these types of risks and benefits.

</details>

<details>
<summary markdown="span">**How can organizations achieve the outcomes of this subcategory?**</summary>

* Reconcile documented concerns about system context of use or purpose against the organization's stated values, mission statements, social responsibility commitments, and AI principles.
* Reconsider the design, implementation strategy, or deployment of AI systems with potential impacts that do not reflect institutional values.

</details>

<details>
<summary markdown="span">**What are the transparency and documentation considerations?**</summary>
<br>
**Transparency Considerations – Key Questions: MAP 1.4**
- What goals and objectives does the entity expect to achieve by designing, developing, and/or deploying the AI system?
- To what extent are the model outputs consistent with the entity’s values and principles to foster public trust and equity?
- To what extent are the metrics consistent with system goals, objectives, and constraints, including ethical and compliance considerations?

**AI Transparency Resources: MAP 1.4**
- GAO-21-519SP: AI Accountability Framework for Federal Agencies & Other Entities
- Intel.gov: AI Ethics Framework for Intelligence Community  - 2020
- WEF Model AI Governance Framework Assessment 2020
- “Including Insights from the Comptroller General’s Forum on the Oversight of Artificial Intelligence An Accountability Framework for Federal Agencies and Other Entities,” 2021

</details>

<details>
<summary markdown="span">**What are some informative references?**</summary>    
<br>
Algorithm Watch. AI Ethics Guidelines Global Inventory. Retrieved from https://inventory.algorithmwatch.org/

Emanuel Moss and Jacob Metcalf. 2020. Ethics Owners: A New Model of Organizational Responsibility in Data-Driven Technology Companies. Data & Society Research Institute. Retrieved from https://datasociety.net/pubs/Ethics-Owners.pdf

Future of Life Institute. Asilomar AI Principles. Retrieved from https://futureoflife.org/2017/08/11/ai-principles/

Leonard Haas, Sebastian Gießler, and Veronika Thiel. 2020. In the realm of paper tigers – exploring the failings of AI ethics guidelines. (April 28, 2020). Retrieved on July 6, 2022 from https://algorithmwatch.org/en/ai-ethics-guidelines-inventory-upgrade-2020/

</details>




