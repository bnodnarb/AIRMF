<!DOCTYPE html>
<link rel="stylesheet" href="https://pages.nist.gov/nist-header-footer/css/nist-combined.css">
      <script src="https://pages.nist.gov/nist-header-footer/js/jquery-1.9.0.min.js" type="text/javascript" defer="defer"></script>
      <script src="https://pages.nist.gov/nist-header-footer/js/nist-header-footer.js" type="text/javascript" defer="defer"></script>


<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1">

		<link rel="stylesheet" href="/RMF/css/screen.css">
		<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Merriweather:400italic,400,300italic,300,700,700italic|Open+Sans:400italic,600italic,700italic,700,600,400|Inconsolata:400,700">

		

		<!-- Begin Jekyll SEO tag v2.4.0 -->
<title>MAP 3.2 | AI RMF Playbook</title>
<meta name="generator" content="Jekyll v3.9.2" />
<meta property="og:title" content="MAP 3.2" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Cost (monetary or otherwise) of errors or unintended system behavior is examined and documented." />
<meta property="og:description" content="Cost (monetary or otherwise) of errors or unintended system behavior is examined and documented." />
<link rel="canonical" href="http://localhost:4000/RMF/map-3/2012/01/16/system-cost.html" />
<meta property="og:url" content="http://localhost:4000/RMF/map-3/2012/01/16/system-cost.html" />
<meta property="og:site_name" content="AI RMF Playbook" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2012-01-16T00:00:00+00:00" />
<script type="application/ld+json">
{"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/RMF/NISTlogo.png"}},"headline":"MAP 3.2","dateModified":"2012-01-16T00:00:00+00:00","datePublished":"2012-01-16T00:00:00+00:00","@type":"BlogPosting","url":"http://localhost:4000/RMF/map-3/2012/01/16/system-cost.html","description":"Cost (monetary or otherwise) of errors or unintended system behavior is examined and documented.","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/RMF/map-3/2012/01/16/system-cost.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

		<link type="application/atom+xml" rel="alternate" href="http://localhost:4000/RMF/feed.xml" title="AI RMF Playbook" />

	</head>

	<body class="">
		<header>
			<div class="wrapper">
				<section class="top-bar">
                                        <nav>
	
	
		
                
                    
                    	 <button class="navbtn scale">
		    	 <a href="/RMF/" >HOME</a>
                         </button>
                    
                
	
	
		
                
                    
                    	 <button class="navbtn scale">
		    	 <a href="/RMF/govern/" >GOVERN</a>
                         </button>
                    
                
	
	
		
                
                    
                    	 <button class="navbtn scale">
		    	 <a href="/RMF/map/" >MAP</a>
                         </button>
                    
                
	
	
		
                
                     <a class="">MEASURE</a>
                
	
	
		
                
                     <a class="">MANAGE</a>
                
	
	
		
                
                    
                    	 <button class="navbtn scale">
		    	 <a href="/RMF/terms/" >TERMS</a>
                         </button>
                    
                
	
	
		
                
                    
       			 <button  class="navbtn scale"><a class="">&nbsp;</a></button>
        		 <button  class="navbtn scale"><a href="/RMF/about/">ABOUT</a></button>
                    
                
	
</nav>


				</section>
				<section class="hero_search">
					<h1>AI Risk Managment Framework Playbook</h1>
				</section>
			</div>

		</header>
		<section class="content">
			<div class="wrapper">
				<section class="tutorial">
	<section class="tutorial-content">
                
                <a href="/RMF/map.html" style="float:right">MAP</a>
                &nbsp&nbsp
	        <br>

                <h2 style="font-family: Arial;"> MAP 3.2 </h2>
              
                <h4 style="font-family: Arial;"> Cost (monetary or otherwise) of errors or unintended system behavior is examined and documented. </h4>

                <br>
		<div class="tutorial-main">
                        
   			   
<details>
  <summary><strong>What is this subcategory about?</strong></summary>
  <p><br />
Anticipating negative impacts of AI systems is a difficult task. Negative impacts can be due to many factors, such as poor system performance, and may range from minor annoyance to serious injury, financial losses, or regulatory enforcement actions. AI actors can work with a broad set of stakeholders to improve their capacity for assessing system impacts – and subsequently – system risks. Hasty or non-thorough impact assessments may result in erroneous determinations of no-risk for more complex or higher risk systems.</p>

</details>

<details>
  <summary><strong>How can organizations achieve the outcomes of this subcategory?</strong></summary>

  <ul>
    <li>Perform a context analysis to map negative impacts arising from not integrating trustworthiness characteristics. When negative impacts are not direct or obvious, AI actors should engage with external stakeholders to investigate and document:
      <ul>
        <li>Who could be harmed?</li>
        <li>What could be harmed?</li>
        <li>When could harm arise?</li>
        <li>How could harm arise?</li>
      </ul>
    </li>
    <li>Implement procedures for regularly evaluating the qualitative and quantitative costs of internal and external AI system failures. Develop actions to prevent, detect, and/or correct  potential risks and related impacts. Regularly evaluate failure costs to inform go/no-go deployment decisions throughout the AI system lifecycle.</li>
  </ul>

</details>

<details>
  <summary><strong>What are the transparency and documentation considerations?</strong></summary>
  <p><br />
<strong>Transparency Considerations – Key Questions: MAP 3.2</strong></p>
  <ul>
    <li>To what extent does the system/entity consistently measure progress towards stated goals and objectives?</li>
    <li>To what extent can users or parties affected by the outputs of the AI system test the AI system and provide feedback?</li>
    <li>Have you documented and explained that machine errors may differ from human errors?</li>
  </ul>

  <p><strong>AI Transparency Resources: MAP 3.2</strong></p>
  <ul>
    <li>Intel.gov: AI Ethics Framework for Intelligence Community  - 2020</li>
    <li>GAO-21-519SP: AI Accountability Framework for Federal Agencies &amp; Other Entities</li>
    <li>Assessment List for Trustworthy AI (ALTAI) - The High-Level Expert Group on AI – 2019</li>
  </ul>

</details>

<details>
  <summary><strong>What are some informative references?</strong></summary>
  <p><br />
Abagayle Lee Blank. 2019. Computer vision machine learning and future-oriented ethics. Honors Project. Seattle Pacific University (SPU), Seattle, WA. Available at https://digitalcommons.spu.edu/cgi/viewcontent.cgi?article=1100&amp;context=honorsprojects</p>

  <p>Margarita Boyarskaya, Alexandra Olteanu, and Kate Crawford. 2020. Overcoming Failures of Imagination in AI Infused System Development and Deployment. arXiv:2011.13416. Retrieved from https://arxiv.org/abs/2011.13416</p>

  <p>Jeff Patton. 2014. User Story Mapping. O’Reilly, Sebastopol, CA. See https://www.jpattonassociates.com/story-mapping/</p>

  <p>Margarita Boenig-Liptsin, Anissa Tanweer &amp; Ari Edmundson (2022) Data Science Ethos Lifecycle: Interplay of ethical thinking and data science practice, Journal of Statistics and Data Science Education, DOI: 10.1080/26939169.2022.2089411</p>

  <p>J. Cohen, D. S. Katz, M. Barker, N. Chue Hong, R. Haines and C. Jay, “The Four Pillars of Research Software Engineering,” in IEEE Software, vol. 38, no. 1, pp. 97-105, Jan.-Feb. 2021, doi: 10.1109/MS.2020.2973362.</p>

  <p>National Academies of Sciences, Engineering, and Medicine 2022. “Introduction” in Fostering Responsible Computing Research: Foundations and Practices. Washington, DC: The National Academies Press. https://doi.org/10.17226/26507.</p>

</details>

			

                </div>
                <br/>
                <br/>
                <a href="/RMF/map-3/2012/01/16/system-cost.html" class="back-to-top">Back to Top &uarr;</a>

	</section>
</section>




			</div>
		</section>

		<footer>
	<div class="wrapper">
		<p class="copyright" style="text-align:center;">&copy; AI RMF Playbook Released August 2022. </p>
	</div>
</footer>



 		<script src="/RMF/js/accordion.js"></script>

	</body>
</html>
