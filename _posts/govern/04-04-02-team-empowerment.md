---
date: 04-04-02
title: GOVERN 4.2
categories:
  - GOVERN-4
description: Organizational teams document the risks and impacts of the technology they design, develop, or deploy and communicate about these impacts more broadly.
type: Govern
order_number: 2
---
{::options parse_block_html="true" /}


<details>
<summary markdown="span">**About**</summary>
<br>
Impact assessments are an approach for driving responsible and ethical technology development practices. And, within a specific use case, these assessments can provide a high-level structure for organizations to frame risks of a given algorithm or deployment. Impact assessments can also serve as a mechanism for organizations to articulate risks and generate documentation for mitigation and oversight activities when harms do arise. 

Impact assessments should be applied at the beginning of a process but also iteratively and regularly since goals and outcomes can evolve over time. It is also important to consider conflicts of interest, or undue influence, related to the organizational team being assessed.

</details>

<details>
<summary markdown="span">**Actions**</summary>
* Establish impact assessment policies and processes for AI systems used by the organization.
* Ensure impact assessment policies are appropriate to evaluate the potential negative impact of a system and how quickly a system changes, and that assessments are applied on a regular basis.
* Ensure impact assessments are utilized to inform broader assessments of AI system risk.

</details>

<details>
<summary markdown="span">**Transparency and Documentation**</summary>
<br>
**Organizations can document the following:**
- How has the entity identified and mitigated potential impacts of bias in the data, including inequitable or discriminatory outcomes?
- How has the entity documented the AI system’s data provenance, including sources, origins, transformations, augmentations, labels, dependencies, constraints, and metadata?
- To what extent has the entity clearly defined technical specifications and requirements for the AI system?"
- To what extent has the entity documented the AI system’s development, testing methodology, metrics, and performance outcomes?
- Have you documented and explained that machine errors may differ from human errors?

**AI Transparency Resources:**
- [GAO-21-519SP: AI Accountability Framework for Federal Agencies & Other Entities](https://www.gao.gov/products/gao-21-519sp)
- [Datasheets for Datasets](http://arxiv.org/abs/1803.09010)

</details>

<details>
<summary markdown="span">**References**</summary>
<br>
Bd. Governors Fed. Rsrv. Sys., Supervisory Guidance on Model Risk Management, SR Letter 11-7 (Apr. 4, 2011)

Patrick Hall, Navdeep Gill, and Benjamin Cox, “Responsible Machine Learning,” O’Reilly Media, 2020. [URL](https://www.oreilly.com/library/view/responsible-machine-learning/9781492090878/)

Off. Superintendent Fin. Inst. Canada, Enterprise-Wide Model Risk Management for Deposit-Taking Institutions, E-23 (Sept. 2017).

GAO, “Artificial Intelligence: An Accountability Framework for Federal Agencies and Other Entities,” GAO@100 (GAO-21-519SP), June 2021. [URL](https://www.gao.gov/assets/gao-21-519sp.pdf)

Donald Sull, Stefano Turconi, and Charles Sull, “When It Comes to Culture, Does Your Company Walk the Talk?” MIT Sloan Mgmt. Rev., 2020. [URL](https://sloanreview.mit.edu/article/when-it-comes-to-culture-does-your-company-walk-the-talk)

Kathy Baxter, AI Ethics Maturity Model, Salesforce. [URL](https://www.salesforceairesearch.com/static/ethics/EthicalAIMaturityModel.pdf)

</details>
