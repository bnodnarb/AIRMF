---
date: 01-03-01
title: MAP 3.1
categories:
  - MAP-3
description: Benefits of intended system behavior are examined and documented.
type: Map
order_number: 1
---

{::options parse_block_html="true" /}


<details>
<summary markdown="span">**About**</summary>
<br>
AI system benefits should counterbalance the inherent risks and implicit and explicit costs. To identify system benefits, organizations should define and document system purpose and utility, along with foreseeable costs, risks, and negative impacts. Credible justification for anticipated benefits beyond the status quo should be clarified and documented.

</details>

<details>
<summary markdown="span">**Actions**</summary>

* Utilize participatory approaches and engage with system end users to evaluate system efficacy and interpretability of AI task output. 
* Incorporate stakeholder feedback about perceived system benefits beyond the status quo. 
* Align system requirements with intended purpose and document decisions. 
* Perform context analysis related to time frame, safety concerns, geographic area, physical environment, ecosystems, social environment, and cultural norms within the intended setting (or conditions that closely approximate the intended setting).

</details>

<details>
<summary markdown="span">**Transparency and Documentation**</summary>
<br>
**Transparency Considerations – Key Questions: MAP 3.1**
- Have the benefits of the AI system been communicated to users?
- Have the appropriate training material and disclaimers about how to adequately use the AI system been provided to users?
- Has your organization implemented a risk management system to address risks involved in deploying the identified AI solution (e.g. personnel risk or changes to commercial objectives)?

**AI Transparency Resources: MAP 3.1**
- Intel.gov: AI Ethics Framework for Intelligence Community  - 2020
- GAO-21-519SP: AI Accountability Framework for Federal Agencies & Other Entities
- Assessment List for Trustworthy AI (ALTAI) - The High-Level Expert Group on AI – 2019

</details>

<details>
<summary markdown="span">**References**</summary>    
<br>
Roel Dobbe, Thomas Krendl Gilbert, and Yonatan Mintz. 2021. Hard choices in artificial intelligence. Artificial Intelligence 300 (14 July 2021), 103555, ISSN 0004-3702. [URL](https://doi.org/10.1016/j.artint.2021.103555)

Samir Passi and Solon Barocas. 2019. Problem Formulation and Fairness. In Proceedings of the Conference on Fairness, Accountability, and Transparency (FAT* '19). Association for Computing Machinery, New York, NY, USA, 39–48. [URL](https://doi.org/10.1145/3287560.3287567)

</details>
