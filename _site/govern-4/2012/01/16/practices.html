<!DOCTYPE html>
<link rel="stylesheet" href="https://pages.nist.gov/nist-header-footer/css/nist-combined.css">
      <script src="https://pages.nist.gov/nist-header-footer/js/jquery-1.9.0.min.js" type="text/javascript" defer="defer"></script>
      <script src="https://pages.nist.gov/nist-header-footer/js/nist-header-footer.js" type="text/javascript" defer="defer"></script>


<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1">

		<link rel="stylesheet" href="/RMF/css/screen.css">
		<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Merriweather:400italic,400,300italic,300,700,700italic|Open+Sans:400italic,600italic,700italic,700,600,400|Inconsolata:400,700">

		

		<!-- Begin Jekyll SEO tag v2.4.0 -->
<title>GOVERN 4.3 | AI RMF Playbook</title>
<meta name="generator" content="Jekyll v3.9.2" />
<meta property="og:title" content="GOVERN 4.3" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Organizational practices are in place to enable testing, identification of incidents, and information sharing." />
<meta property="og:description" content="Organizational practices are in place to enable testing, identification of incidents, and information sharing." />
<link rel="canonical" href="http://localhost:4000/RMF/govern-4/2012/01/16/practices.html" />
<meta property="og:url" content="http://localhost:4000/RMF/govern-4/2012/01/16/practices.html" />
<meta property="og:site_name" content="AI RMF Playbook" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2012-01-16T00:00:00+00:00" />
<script type="application/ld+json">
{"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/RMF/NISTlogo.png"}},"headline":"GOVERN 4.3","dateModified":"2012-01-16T00:00:00+00:00","datePublished":"2012-01-16T00:00:00+00:00","@type":"BlogPosting","url":"http://localhost:4000/RMF/govern-4/2012/01/16/practices.html","description":"Organizational practices are in place to enable testing, identification of incidents, and information sharing.","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/RMF/govern-4/2012/01/16/practices.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

		<link type="application/atom+xml" rel="alternate" href="http://localhost:4000/RMF/feed.xml" title="AI RMF Playbook" />

	</head>

	<body class="">
		<header>
			<div class="wrapper">
				<section class="top-bar">
                                        <nav>
	
	
		
                
                    
                    	 <button class="navbtn scale">
		    	 <a href="/RMF/" >HOME</a>
                         </button>
                    
                
	
	
		
                
                    
                    	 <button class="navbtn scale">
		    	 <a href="/RMF/govern/" >GOVERN</a>
                         </button>
                    
                
	
	
		
                
                    
                    	 <button class="navbtn scale">
		    	 <a href="/RMF/map/" >MAP</a>
                         </button>
                    
                
	
	
		
                
                     <a class="">MEASURE</a>
                
	
	
		
                
                     <a class="">MANAGE</a>
                
	
	
		
                
                    
                    	 <button class="navbtn scale">
		    	 <a href="/RMF/terms/" >TERMS</a>
                         </button>
                    
                
	
	
		
                
                    
       			 <button  class="navbtn scale"><a class="">&nbsp;</a></button>
        		 <button  class="navbtn scale"><a href="/RMF/about/">ABOUT</a></button>
                    
                
	
</nav>


				</section>
				<section class="hero_search">
					<h1>AI Risk Managment Framework Playbook</h1>
				</section>
			</div>

		</header>
		<section class="content">
			<div class="wrapper">
				<section class="tutorial">
	<section class="tutorial-content">
                
                <a href="/RMF/Govern" style="float:right">GOVERN</a>
                &nbsp&nbsp
	        <br>

                <h2 style="font-family: Arial;"> GOVERN 4.3 </h2>
              
                <h4 style="font-family: Arial;"> Organizational practices are in place to enable testing, identification of incidents, and information sharing. </h4>

                <br>
		<div class="tutorial-main">
                        
   			   
<details>
  <summary><strong>What is this subcategory about?</strong></summary>
  <p><br />
Organizations committed to risk management acknowledge the importance of identifying AI system limitations, detecting and tracking negative impacts and incidents, and sharing information about these issues with appropriate AI actors. Building organizational capacity requires policies and procedures connected to testing and inquiry.</p>

  <p>Issues such as concept drift, AI bias and discrimination, shortcut learning or underspecification are difficult to identify using standard AI testing processes. Organizations can institute in-house use and testing policies and procedures to identify and manage such issues. Efforts can take the form of pre-alpha or pre-beta testing, or deploying internally developed systems or products within the organization. Testing may entail limited and controlled in-house, or publicly available, AI system testbeds.</p>

  <p>Without policies and procedures that enable consistent testing practices, risk management efforts may be bypassed or ignored, exacerbating risks or leading to inconsistent risk management activities.</p>

  <p>Information sharing about impacts or incidents detected during testing or deployment can:</p>
  <ul>
    <li>draw attention to AI system risks, failures, abuses and misuses,</li>
    <li>allow organizations to benefit from insights based on a wide range of AI applications and implementations, and</li>
    <li>allow organizations to be more proactive in avoiding known failure modes.</li>
  </ul>

</details>

<details>
  <summary><strong>How can organizations achieve the outcomes of this subcategory?</strong></summary>
  <ul>
    <li>Establish policies and procedures to facilitate and equip AI system testing.</li>
    <li>Establish organizational commitment to identifying AI system limitations and sharing of insights about limitations within appropriate AI actor groups.</li>
    <li>Establish guidelines for handling and access control related to AI system risks and performance.</li>
  </ul>

</details>

<details>
  <summary><strong>What are the transparency and documentation considerations?</strong></summary>
  <p><br />
Column G goes here.</p>

</details>

<details>
  <summary><strong>What are some informative references?</strong></summary>
  <p><br />
S. McGregor, “Preventing Repeated Real World AI Failures by Cataloging Incidents: The AI Incident Database,” arXiv:2011.08512 [cs], Nov. 2020, arXiv:2011.08512. [Online]. Available: http://arxiv.org/abs/2011.08512</p>

  <p>C. Johnson, M. Badger, D. Waltermire, J. Snyder, and C. Skorupka, “Guide to cyber threat information sharing,” National Institute of Standards and Technology, NIST Special Publication 800-150, Nov 2016. [Online]. Available: https://doi.org/10.6028/NIST.SP.800-150</p>

</details>

			

                </div>
                <br/>
                <br/>
                <a href="/RMF/govern-4/2012/01/16/practices.html" class="back-to-top">Back to Top &uarr;</a>

	</section>
</section>




			</div>
		</section>

		<footer>
	<div class="wrapper">
		<p class="copyright" style="text-align:center;">&copy; AI RMF Playbook Released August 2022. </p>
	</div>
</footer>



 		<script src="/RMF/js/accordion.js"></script>

	</body>
</html>
