---
layout: default
title: terms
description:
permalink:
---
<head>
<link rel="stylesheet" href="{{ site.baseurl }}/css/fonts/font-awesome.min.css">
</head>

<button class="btn" style="float:right"><a href="{{ site.baseurl }}/terms/terms.pdf" download><i class="fa fa-download">&nbsp;&nbsp;&nbsp;&nbsp;</i></a></button>


**<u>AI Actors and Tasks</u>**

**AI Design** actors create the concept and objectives of AI systems and are responsible for the planning, design, and data collection and processing tasks of the AI system so that the AI system is lawful and fit-for-purpose. Tasks include articulating and documenting the system’s concept and objectives, underlying assumptions, context, and requirements; gathering and cleaning data; and documenting the metadata and characteristics of the dataset. 

**AI Development** actors provide the initial infrastructure of AI systems and are responsible
for model building and interpretation tasks, which involve the creation, selection, calibration,
training, and/or testing of models or algorithms. 

**AI Deployment** actors are responsible for contextual decisions relating to how the AI system is used to assure deployment of the system into production. Related tasks include piloting the system, checking compatibility with legacy systems, ensuring regulatory compliance, managing organizational change, and evaluating user experience. 

**Operation and Monitoring** tasks are performed by AI actors who are responsible for operating the AI system and working with others to continuously assess system output and impacts. 

**Test, Evaluation, Verification, and Validation (TEVV)** tasks are performed  by AI actors who examine the AI system or its components, or detect and remediate problems. Ideally, AI actors carrying out verification and validation tasks are distinct from those who perform test and evaluation actions. Tasks can be incorporated into a phase as early as design, where tests are planned in accordance with the design requirement.
- TEVV tasks for design, planning, and data may center on internal and external validation
of assumptions for system design, data collection, and measurements relative
to the intended context of deployment or application.
- TEVV tasks for development (i.e., model building) include model validation and assessment.
- TEVV tasks for deployment include system validation and integration in production,
with testing, and recalibration for systems and process integration, user experience,
and compliance with existing legal, regulatory, and ethical specifications.
- TEVV tasks for operations involve ongoing monitoring for periodic updates, testing,
and subject matter expert (SME) recalibration of models, the tracking of incidents
or errors reported and their management, the detection of emergent properties and
related impacts, and processes for redress and response.

**Human Factors tasks** and activities include human-centered design practices and methodologies, promoting the active involvement of end users and other interested parties and relevant AI actors, incorporating context-specific norms and values in system design, evaluating and adapting end user experiences, and broad integration of humans and human dynamics in all phases of the AI lifecycle. Human factors professionals provide multidisciplinary skills and perspectives to understand context of use, inform interdisciplinary and demographic diversity, engage in consultative processes, design and evaluate user experience, perform human-centered evaluation and testing, and inform impact assessments.

**Domain Expert** tasks involve input from multidisciplinary practitioners or scholars who
provide knowledge or expertise in – and about – an industry sector, economic sector, context,
or application area where an AI system is being used. AI actors who are domain
experts can provide essential guidance for AI system design and development, and interpret
outputs in support of work performed by TEVV and AI impact assessment teams.

**AI Impact Assessment** tasks include assessing and evaluating requirements for AI system
accountability, combating harmful bias, examining impacts of AI systems, product safety,
liability, and security, among others. AI actors such as impact assessors and evaluators
provide technical, human factor, socio-cultural, and legal expertise.

**Procurement** actors maintain financial, legal, or policy management authority for acquisition of AI models, products, or services from a third-party, developer, vendor, or contractor.

**Governance and Oversight** actors maintain management, fiduciary, and legal authority and responsibility for the organization in which an AI system is designed, developed, and/or deployed, including organizational management, senior leadership, and the Board of Directors.

**<u>Additional AI Actors</u>**

**Third-party** entities are actors external to the design, development, or deployment team of the organization that acquires its technologies or services and are responsible for AI design and development tasks, in whole or in part. 

**End users** are the individuals or groups that use the system for specific purposes. These individuals or groups interact with an AI system in a specific context. End users can range in competency from AI experts to first-time technology end users.

**Affected individuals/communities** encompass all individuals, groups, communities, or
organizations directly or indirectly affected by AI systems or decisions based on the output
of AI systems. These individuals do not necessarily interact with the deployed system or
application.

**Other AI actors** may provide formal or quasi-formal norms or guidance for specifying and managing AI risks. They can include **trade associations, standards developing organizations, advocacy groups, researchers, environmental groups, and civil society organizations.**

**The general public** is most likely to directly experience positive and negative impacts of
AI technologies. They may provide the motivation for actions taken by the AI actors. This
group can include individuals, communities, and consumers associated with the context in
which an AI system is developed or deployed.

