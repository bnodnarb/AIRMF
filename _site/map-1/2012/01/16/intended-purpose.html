<!DOCTYPE html>
<link rel="stylesheet" href="https://pages.nist.gov/nist-header-footer/css/nist-combined.css">
      <script src="https://pages.nist.gov/nist-header-footer/js/jquery-1.9.0.min.js" type="text/javascript" defer="defer"></script>
      <script src="https://pages.nist.gov/nist-header-footer/js/nist-header-footer.js" type="text/javascript" defer="defer"></script>


<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1">

		<link rel="stylesheet" href="/RMF/css/screen.css">
		<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Merriweather:400italic,400,300italic,300,700,700italic|Open+Sans:400italic,600italic,700italic,700,600,400|Inconsolata:400,700">

		

		<!-- Begin Jekyll SEO tag v2.4.0 -->
<title>MAP 1.1 | AI RMF Playbook</title>
<meta name="generator" content="Jekyll v3.9.2" />
<meta property="og:title" content="MAP 1.1" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Intended purpose, setting in which the AI system will be deployed, the specific set of users along with their expectations, and impacts of system use are understood and documented. Assumptions and related limitations about AI system purpose and use are enumerated." />
<meta property="og:description" content="Intended purpose, setting in which the AI system will be deployed, the specific set of users along with their expectations, and impacts of system use are understood and documented. Assumptions and related limitations about AI system purpose and use are enumerated." />
<link rel="canonical" href="http://localhost:4000/RMF/map-1/2012/01/16/intended-purpose.html" />
<meta property="og:url" content="http://localhost:4000/RMF/map-1/2012/01/16/intended-purpose.html" />
<meta property="og:site_name" content="AI RMF Playbook" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2012-01-16T00:00:00+00:00" />
<script type="application/ld+json">
{"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/RMF/NISTlogo.png"}},"headline":"MAP 1.1","dateModified":"2012-01-16T00:00:00+00:00","datePublished":"2012-01-16T00:00:00+00:00","@type":"BlogPosting","url":"http://localhost:4000/RMF/map-1/2012/01/16/intended-purpose.html","description":"Intended purpose, setting in which the AI system will be deployed, the specific set of users along with their expectations, and impacts of system use are understood and documented. Assumptions and related limitations about AI system purpose and use are enumerated.","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/RMF/map-1/2012/01/16/intended-purpose.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

		<link type="application/atom+xml" rel="alternate" href="http://localhost:4000/RMF/feed.xml" title="AI RMF Playbook" />

	</head>

	<body class="">
		<header>
			<div class="wrapper">
				<section class="top-bar">
                                        <nav>
	
	
		
                
                    
                    	 <button class="navbtn scale">
		    	 <a href="/RMF/" >HOME</a>
                         </button>
                    
                
	
	
		
                
                    
                    	 <button class="navbtn scale">
		    	 <a href="/RMF/govern/" >GOVERN</a>
                         </button>
                    
                
	
	
		
                
                    
                    	 <button class="navbtn scale">
		    	 <a href="/RMF/map/" >MAP</a>
                         </button>
                    
                
	
	
		
                
                     <a class="">MEASURE</a>
                
	
	
		
                
                     <a class="">MANAGE</a>
                
	
	
		
                
                    
                    	 <button class="navbtn scale">
		    	 <a href="/RMF/terms/" >TERMS</a>
                         </button>
                    
                
	
	
		
                
                    
       			 <button  class="navbtn scale"><a class="">&nbsp;</a></button>
        		 <button  class="navbtn scale"><a href="/RMF/about/">ABOUT</a></button>
                    
                
	
</nav>


				</section>
				<section class="hero_search">
					<h1>AI Risk Managment Framework Playbook</h1>
				</section>
			</div>

		</header>
		<section class="content">
			<div class="wrapper">
				<section class="tutorial">
	<section class="tutorial-content">
                
                <a href="/RMF/Map" style="float:right">MAP</a>
                &nbsp&nbsp
	        <br>

                <h2 style="font-family: Arial;"> MAP 1.1 </h2>
              
                <h4 style="font-family: Arial;"> Intended purpose, setting in which the AI system will be deployed, the specific set of users along with their expectations, and impacts of system use are understood and documented. Assumptions and related limitations about AI system purpose and use are enumerated. </h4>

                <br>
		<div class="tutorial-main">
                        
   			   
<details>
  <summary><strong>What is this subcategory about?</strong></summary>
  <p><br />
Mapping context may include examination of the following:</p>
  <ul>
    <li>intended and actual deployment setting.</li>
    <li>specific set of users.</li>
    <li>operator or subject expectations.</li>
    <li>concept of operations.</li>
    <li>intended purpose and impact of system use.</li>
    <li>requirements for system deployment and operation.</li>
    <li>potential negative impacts to individuals, groups, communities, organizations, and society – or context-specific impacts such as legal requirements or impacts to the environment.</li>
    <li>unintended, downstream, or other unknown contextual factors.</li>
  </ul>

</details>

<details>
  <summary><strong>How can organizations achieve the outcomes of this subcategory?</strong></summary>

  <ul>
    <li>Pursue AI system design purposefully, after non-AI solutions are considered.</li>
    <li>Collaboratively consider intended AI system design tasks along with unanticipated purposes.</li>
    <li>Maintain awareness of industry, technical, and applicable legal standards.</li>
    <li>Track and document existing AI systems held by the organization, and those maintained or supported by third-party entities.</li>
    <li>Gain and maintain awareness about evaluating scientific claims related to AI system performance and benefits before launching into system design.</li>
    <li>Define and document the task, purpose, minimum functionality, and benefits of the AI system to inform considerations about whether the project is worth pursuing.</li>
    <li>Define the AI system context of use, including:
      <ul>
        <li>operational environment</li>
        <li>impacts to individuals, groups, communities, organizations, and society</li>
        <li>user characteristics and tasks</li>
        <li>social environment.</li>
      </ul>
    </li>
    <li>Determine the user and organizational requirements, including business and technical requirements.</li>
    <li>Identify human-AI interaction and/or roles, such as whether the application will support or replace human decision making.</li>
    <li>Plan for risks related to human-AI configurations, and document requirements, roles, and responsibilities for human oversight of deployed systems.</li>
  </ul>

</details>

<details>
  <summary><strong>What are the transparency and documentation considerations?</strong></summary>

  <p><strong>Transparency Considerations – Key Questions: MAP 1.1</strong></p>
  <ul>
    <li>Who is ultimately responsible for the decisions of the AI and is this person aware of the intended uses and limitations of the analytic?</li>
    <li>Who will be responsible for maintaining, re-verifying, monitoring, and updating this AI once deployed?</li>
    <li>Who is accountable for the ethical considerations during all stages of the AI lifecycle?</li>
    <li>Why was the dataset created? (e.g., were there specific tasks in mind, or a specific gap that needed to be filled?</li>
    <li>How does the entity ensure that the data collected are adequate, relevant, and not excessive in relation to the intended purpose?</li>
  </ul>

  <p><strong>AI Transparency Resources: MAP 1.1</strong></p>
  <ul>
    <li>Datasheets for Datasets</li>
    <li>GAO-21-519SP: AI Accountability Framework for Federal Agencies &amp; Other Entities</li>
    <li>“Stakeholders in Explainable AI,” Sep. 2018, [Online]. <a href="http://arxiv.org/abs/1810.00184">link</a></li>
  </ul>

</details>

<details>
  <summary><strong>What are some informative references?</strong></summary>
  <p><br />
<strong>Socio-technical systems</strong></p>

  <p>Andrew D. Selbst, Danah Boyd, Sorelle A. Friedler, et al. 2019. Fairness and Abstraction in Sociotechnical Systems. In Proceedings of the Conference on Fairness, Accountability, and Transparency (FAT* ‘19). Association for Computing Machinery, New York, NY, USA, 59–68. https://doi.org/10.1145/3287560.3287598</p>

  <p><strong>Problem formulation</strong></p>

  <p>Roel Dobbe, Thomas Krendl Gilbert, and Yonatan Mintz. 2021. Hard choices in artificial intelligence. Artificial Intelligence 300 (14 July 2021), 103555, ISSN 0004-3702. DOI: https://doi.org/10.1016/j.artint.2021.103555</p>

  <p>Samir Passi and Solon Barocas. 2019. Problem Formulation and Fairness. In Proceedings of the Conference on Fairness, Accountability, and Transparency (FAT* ‘19). Association for Computing Machinery, New York, NY, USA, 39–48. https://doi.org/10.1145/3287560.3287567</p>

  <p><strong>Context mapping</strong></p>

  <p>Emilio Gómez-González and Emilia Gómez. 2020. Artificial intelligence in medicine and healthcare. Joint Research Centre (European Commission). Retrieved from https://op.europa.eu/en/publication-detail/-/publication/b4b5db47-94c0-11ea-aac4-01aa75ed71a1/language-en</p>

  <p>Sarah Spiekermann and Till Winkler. 2020. Value-based Engineering for Ethics by Design. arXiv:2004.13676. Retrieved from https://arxiv.org/abs/2004.13676</p>

  <p>Social Impact Lab. 2017. Framework for Context Analysis of Technologies in Social Change Projects (Draft v2.0). Retrieved from https://www.alnap.org/system/files/content/resource/files/main/Draft%20SIMLab%20Context%20Analysis%20Framework%20v2.0.pdf</p>

  <p>Solon Barocas, Asia J. Biega, Margarita Boyarskaya, et al. 2021. Responsible computing during COVID-19 and beyond. Commun. ACM 64, 7 (July 2021), 30–32. https://doi.org/10.1145/3466612</p>

  <p><strong>Identification of harms</strong></p>

  <p>Harini Suresh and John V. Guttag. 2020. A Framework for Understanding Sources of Harm throughout the Machine Learning Life Cycle. arXiv:1901.10002. Retrieved from https://arxiv.org/abs/1901.10002</p>

  <p>Margarita Boyarskaya, Alexandra Olteanu, and Kate Crawford. 2020. Overcoming Failures of Imagination in AI Infused System Development and Deployment. arXiv:2011.13416. Retrieved from https://arxiv.org/abs/2011.13416</p>

  <p><strong>Measurement and evaluation</strong></p>

  <p>Abigail Z. Jacobs and Hanna Wallach. 2021. Measurement and Fairness. In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency (FAccT ‘21). Association for Computing Machinery, New York, NY, USA, 375–385. https://doi.org/10.1145/3442188.3445901</p>

  <p>Ben Hutchinson, Negar Rostamzadeh, Christina Greer, et al. 2022. Evaluation Gaps in Machine Learning Practice. arXiv:2205.05256. Retrieved from https://arxiv.org/abs/2205.05256</p>

  <p><strong>Understanding and documenting limitations in ML</strong></p>

  <p>Alexander D’Amour, Katherine Heller, Dan Moldovan, et al. 2020. Underspecification Presents Challenges for Credibility in Modern Machine Learning. arXiv:2011.03395. Retrieved from https://arxiv.org/abs/2011.03395</p>

  <p>Jessie J. Smith, Saleema Amershi, Solon Barocas, et al. 2022. REAL ML: Recognizing, Exploring, and Articulating Limitations of Machine Learning Research. arXiv:2205.08363. Retrieved from https://arxiv.org/abs/2205.08363</p>

  <p>Margaret Mitchell, Simone Wu, Andrew Zaldivar, et al. 2019. Model Cards for Model Reporting. In Proceedings of the Conference on Fairness, Accountability, and Transparency (FAT* ‘19). Association for Computing Machinery, New York, NY, USA, 220–229. https://doi.org/10.1145/3287560.3287596</p>

  <p>Matthew Arnold, Rachel K. E. Bellamy, Michael Hind, et al. 2019. FactSheets: Increasing Trust in AI Services through Supplier’s Declarations of Conformity. arXiv:1808.07261. Retrieved from https://arxiv.org/abs/1808.07261</p>

  <p>Michael A. Madaio, Luke Stark, Jennifer Wortman Vaughan, and Hanna Wallach. 2020. Co-Designing Checklists to Understand Organizational Challenges and Opportunities around Fairness in AI. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (CHI ‘20). Association for Computing Machinery, New York, NY, USA, 1–14. https://doi.org/10.1145/3313831.3376445</p>

  <p>Timnit Gebru, Jamie Morgenstern, Briana Vecchione, et al. 2021. Datasheets for Datasets. arXiv:1803.09010. Retrieved from https://arxiv.org/abs/1803.09010</p>

  <p>Bender, E. M., Friedman, B. &amp; McMillan-Major, A.,  (2022). A Guide for Writing Data Statements for Natural Language Processing. University of Washington.  Accessed July 14, 2022. .https://techpolicylab.uw.edu/wp-content/uploads/2021/11/Data_Statements_Guide_V2.pdf</p>

  <p><strong>When not to deploy</strong></p>

  <p>Solon Barocas, Asia J. Biega, Benjamin Fish, et al. 2020. When not to design, build, or deploy. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency (FAT* ‘20). Association for Computing Machinery, New York, NY, USA, 695. https://doi.org/10.1145/3351095.3375691</p>

  <p><strong>Statistical balance</strong></p>

  <p>Ziad Obermeyer, Brian Powers, Christine Vogeli, and Sendhil Mullainathan. 2019. Dissecting racial bias in an algorithm used to manage the health of populations. Science 366, 6464 (25 Oct. 2019), 447-453. DOI: https://doi.org/10.1126/science.aax2342</p>

  <p><strong>Assessment of science in AI</strong></p>

  <p>Arvind Narayanan. How to recognize AI snake oil. Retrieved July 6, 2022 from https://www.cs.princeton.edu/~arvindn/talks/MIT-STS-AI-snakeoil.pdf</p>

  <p>Emily M. Bender. 2022. On NYT Magazine on AI: Resist the Urge to be Impressed. (April 17, 2022). Retrieved July 6, 2022 from https://medium.com/@emilymenonbender/on-nyt-magazine-on-ai-resist-the-urge-to-be-impressed-3d92fd9a0edd</p>

</details>

			

                </div>
                <br/>
                <br/>
                <a href="/RMF/map-1/2012/01/16/intended-purpose.html" class="back-to-top">Back to Top &uarr;</a>

	</section>
</section>




			</div>
		</section>

		<footer>
	<div class="wrapper">
		<p class="copyright" style="text-align:center;">&copy; AI RMF Playbook Released August 2022. </p>
	</div>
</footer>



 		<script src="/RMF/js/accordion.js"></script>

	</body>
</html>
