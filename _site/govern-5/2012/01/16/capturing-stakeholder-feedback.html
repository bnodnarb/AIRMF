<!DOCTYPE html>
<link rel="stylesheet" href="https://pages.nist.gov/nist-header-footer/css/nist-combined.css">
      <script src="https://pages.nist.gov/nist-header-footer/js/jquery-1.9.0.min.js" type="text/javascript" defer="defer"></script>
      <script src="https://pages.nist.gov/nist-header-footer/js/nist-header-footer.js" type="text/javascript" defer="defer"></script>


<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1">

		<link rel="stylesheet" href="/RMF/css/screen.css">
		<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Merriweather:400italic,400,300italic,300,700,700italic|Open+Sans:400italic,600italic,700italic,700,600,400|Inconsolata:400,700">

		

		<!-- Begin Jekyll SEO tag v2.4.0 -->
<title>GOVERN 5.1 | AI RMF Playbook</title>
<meta name="generator" content="Jekyll v3.9.2" />
<meta property="og:title" content="GOVERN 5.1" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Organizational policies and practices are in place to prioritize the consideration and adjudication of external stakeholder feedback regarding the potential individual and societal impacts related to AI risks." />
<meta property="og:description" content="Organizational policies and practices are in place to prioritize the consideration and adjudication of external stakeholder feedback regarding the potential individual and societal impacts related to AI risks." />
<link rel="canonical" href="http://localhost:4000/RMF/govern-5/2012/01/16/capturing-stakeholder-feedback.html" />
<meta property="og:url" content="http://localhost:4000/RMF/govern-5/2012/01/16/capturing-stakeholder-feedback.html" />
<meta property="og:site_name" content="AI RMF Playbook" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2012-01-16T00:00:00+00:00" />
<script type="application/ld+json">
{"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/RMF/NISTlogo.png"}},"headline":"GOVERN 5.1","dateModified":"2012-01-16T00:00:00+00:00","datePublished":"2012-01-16T00:00:00+00:00","@type":"BlogPosting","url":"http://localhost:4000/RMF/govern-5/2012/01/16/capturing-stakeholder-feedback.html","description":"Organizational policies and practices are in place to prioritize the consideration and adjudication of external stakeholder feedback regarding the potential individual and societal impacts related to AI risks.","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/RMF/govern-5/2012/01/16/capturing-stakeholder-feedback.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

		<link type="application/atom+xml" rel="alternate" href="http://localhost:4000/RMF/feed.xml" title="AI RMF Playbook" />

	</head>

	<body class="">
		<header>
			<div class="wrapper">
				<section class="top-bar">
                                        <nav>
	
	
		
                
                    
                    	 <button class="navbtn scale">
		    	 <a href="/RMF/" >HOME</a>
                         </button>
                    
                
	
	
		
                
                    
                    	 <button class="navbtn scale">
		    	 <a href="/RMF/govern/" >GOVERN</a>
                         </button>
                    
                
	
	
		
                
                    
                    	 <button class="navbtn scale">
		    	 <a href="/RMF/map/" >MAP</a>
                         </button>
                    
                
	
	
		
                
                     <a class="">MEASURE</a>
                
	
	
		
                
                     <a class="">MANAGE</a>
                
	
	
		
                
                    
                    	 <button class="navbtn scale">
		    	 <a href="/RMF/terms/" >TERMS</a>
                         </button>
                    
                
	
	
		
                
                    
       			 <button  class="navbtn scale"><a class="">&nbsp;</a></button>
        		 <button  class="navbtn scale"><a href="/RMF/about/">ABOUT</a></button>
                    
                
	
</nav>


				</section>
				<section class="hero_search">
					<h1>AI Risk Managment Framework Playbook</h1>
				</section>
			</div>

		</header>
		<section class="content">
			<div class="wrapper">
				<section class="tutorial">
	<section class="tutorial-content">
                
                <a href="/RMF/govern.html" style="float:right">GOVERN</a>
                &nbsp&nbsp
	        <br>

                <h2 style="font-family: Arial;"> GOVERN 5.1 </h2>
              
                <h4 style="font-family: Arial;"> Organizational policies and practices are in place to prioritize the consideration and adjudication of external stakeholder feedback regarding the potential individual and societal impacts related to AI risks. </h4>

                <br>
		<div class="tutorial-main">
                        
   			   
<details>
  <summary><strong>What is this subcategory about?</strong></summary>
  <p><br />
Internal and laboratory-based system testing is crucially important, but the true test of an AI system is whether it is fit for purpose in a real-world setting, its risk is managed and its negative impact is minimized.</p>

  <p>Participatory stakeholder engagement is one type of qualitative activity to help AI actor teams answer questions such as whether to pursue a project or how to design with impact in mind. The consideration of how to convene a group and the kinds of individuals, groups, or community organizations to include is an iterative process connected to the purpose of the system being pursued. Other factors relate to how to collaboratively and respectfully capture stakeholder feedback and insight that is useful, without being a solely perfunctory exercise.</p>

  <p>These activities are best carried out by personnel with expertise in participatory practices, qualitative methods, and translation of contextual feedback for technical audiences.</p>

  <p>Participatory engagement is not a one-time exercise and should be carried out from the very beginning of AI system commissioning through the end of the lifecycle. Organizations can consider how to incorporate engagement when beginning a project and as part of their monitoring of systems. Engagement is often utilized as a consultative practice, but this perspective may inadvertently lead to “participation washing.”  Organizational transparency about the purpose and goal of the engagement can help mitigate that possibility.</p>

</details>

<details>
  <summary><strong>How can organizations achieve the outcomes of this subcategory?</strong></summary>
  <ul>
    <li>Ensure AI risk management policies address explicit mechanisms for receiving, processing, and implementing stakeholder and user feedback that could include:
      <ul>
        <li>Recourse mechanisms for faulty AI system outputs.</li>
        <li>Bug bounties.</li>
        <li>Human-centered design.</li>
        <li>User-interaction and experience research.</li>
        <li>Participatory stakeholder engagement with individuals and communities that may experience negative impacts.</li>
      </ul>
    </li>
    <li>Ensure that stakeholder feedback is considered and addressed, including environmental concerns, and across the entire population of intended users, including historically excluded populations, people with disabilities, older people, and those with limited access to the internet and other basic technologies.</li>
    <li>Clarify the organization’s principles as they apply to AI systems – considering those which have been proposed publicly – to inform external stakeholders of the organization’s values. Consider publishing or adopting AI principles.</li>
  </ul>

</details>

<details>
  <summary><strong>What are the transparency and documentation considerations?</strong></summary>
  <p><br />
Column G goes here.</p>

</details>

<details>
  <summary><strong>What are some informative references?</strong></summary>
  <p><br />
ISO, “Ergonomics of human-system interaction — Part 210: Human-centered design for interactive systems,” ISO 9241-210:2019 (2nd ed.), July 2019, https://www.iso.org/standard/77520.html.</p>

  <p>Rumman Chowdhury and Jutta Williams, “Introducing Twitter’s first algorithmic bias bounty challenge,” https://blog.twitter.com/engineering/en_us/topics/insights/2021/algorithmic-bias-bounty-challenge.</p>

  <p>Leonard Haas and Sebastian Gießler, “In the realm of paper tigers – exploring the failings of AI ethics guidelines,” AlgorithmWatch, 2020, available at https://algorithmwatch.org/en/ai-ethics-guidelines-inventory-upgrade-2020/.</p>

  <p>Josh Kenway, Camille Francois, Dr. Sasha Costanza-Chock, Inioluwa Deborah Raji, &amp; Dr. Joy Buolamwini. 2022. Bug Bounties for Algorithmic Harms? Algorithmic Justice League. Accessed July 14, 2022. https://www.ajl.org/bugs</p>

</details>

			

                </div>
                <br/>
                <br/>
                <a href="/RMF/govern-5/2012/01/16/capturing-stakeholder-feedback.html" class="back-to-top">Back to Top &uarr;</a>

	</section>
</section>




			</div>
		</section>

		<footer>
	<div class="wrapper">
		<p class="copyright" style="text-align:center;">&copy; AI RMF Playbook Released August 2022. </p>
	</div>
</footer>



 		<script src="/RMF/js/accordion.js"></script>

	</body>
</html>
