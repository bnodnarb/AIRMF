---
date: 01-05-02
title: MAP 5.2
categories:
  - MAP-5
description: Likelihood and magnitude of each identified impact based on expected use, past uses of AI systems in similar contexts, public incident reports, stakeholder feedback, or other data are identified and documented.
type: Map
order_number: 2
---

{::options parse_block_html="true" /}


<details>
<summary markdown="span">**What is this subcategory about?**</summary>
<br>
The likelihood of AI system impacts identified in Map 5.1 should be evaluated. Potential impacts should be documented and triaged. 

Likelihood estimates may then be assessed and judged for go/no-go decisions about deploying an AI system. If an organization decides to proceed with deploying the system, the likelihood estimate can be used to assign oversight resources appropriate for the  risk level.

</details>

<details>
<summary markdown="span">**How can organizations achieve the outcomes of this subcategory?**</summary>

* Establish assessment scales for measuring AI system impact. Scales may be qualitative, such as red-amber-green (RAG), or may entail simulations or econometric approaches. Document and apply scales uniformly across the organization’s AI portfolio. 
* Apply impact assessments regularly at key stages in the AI lifecycle, connected to system impacts and frequency of system updates. 
* Assess system benefits and negative impacts in relation to trustworthy characteristics.

</details>

<details>
<summary markdown="span">**What are the transparency and documentation considerations?**</summary>
<br>
**Transparency Considerations – Key Questions: MAP 5.2**
- Which population(s) does the AI system impact?
- What assessments has the entity conducted on data security and privacy impacts associated with the AI system?
- Did you ensure that the AI system can be audited by independent third parties?

**AI Transparency Resources: MAP 5.2**
- Datasheets for Datasets
- GAO-21-519SP: AI Accountability Framework for Federal Agencies & Other Entities
- “AI policies and initiatives,” in Artificial Intelligence in Society, OECD, 2019
- Intel.gov: AI Ethics Framework for Intelligence Community  - 2020
- Assessment List for Trustworthy AI (ALTAI) - The High-Level Expert Group on AI - 2019

</details>

<details>
<summary markdown="span">**What are some informative references?**</summary>
<br>
Emilio Gómez-González and Emilia Gómez. 2020. Artificial intelligence in medicine and healthcare. Joint Research Centre (European Commission). Retrieved from [op.europa.eu](https://op.europa.eu/en/publication-detail/-/publication/b4b5db47-94c0-11ea-aac4-01aa75ed71a1/language-en)

Artificial Intelligence Incident Database. 2022. Retrieved from [Incidentdatabase](https://incidentdatabase.ai/?lang=en)
</details>
