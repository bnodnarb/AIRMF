<!DOCTYPE html>
<link rel="stylesheet" href="https://pages.nist.gov/nist-header-footer/css/nist-combined.css">
      <script src="https://pages.nist.gov/nist-header-footer/js/jquery-1.9.0.min.js" type="text/javascript" defer="defer"></script>
      <script src="https://pages.nist.gov/nist-header-footer/js/nist-header-footer.js" type="text/javascript" defer="defer"></script>


<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1">

		<link rel="stylesheet" href="/RMF/css/screen.css">
		<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Merriweather:400italic,400,300italic,300,700,700italic|Open+Sans:400italic,600italic,700italic,700,600,400|Inconsolata:400,700">

		

		<!-- Begin Jekyll SEO tag v2.4.0 -->
<title>GOVERN 4.1 | AI RMF Playbook</title>
<meta name="generator" content="Jekyll v3.9.2" />
<meta property="og:title" content="GOVERN 4.1" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Organizational practices are in place to foster a critical thinking mindset in the design, development, and deployment of AI systems to minimize negative impacts." />
<meta property="og:description" content="Organizational practices are in place to foster a critical thinking mindset in the design, development, and deployment of AI systems to minimize negative impacts." />
<link rel="canonical" href="http://localhost:4000/RMF/govern-4/2012/01/16/teams-and-communications.html" />
<meta property="og:url" content="http://localhost:4000/RMF/govern-4/2012/01/16/teams-and-communications.html" />
<meta property="og:site_name" content="AI RMF Playbook" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2012-01-16T00:00:00+00:00" />
<script type="application/ld+json">
{"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/RMF/NISTlogo.png"}},"headline":"GOVERN 4.1","dateModified":"2012-01-16T00:00:00+00:00","datePublished":"2012-01-16T00:00:00+00:00","@type":"BlogPosting","url":"http://localhost:4000/RMF/govern-4/2012/01/16/teams-and-communications.html","description":"Organizational practices are in place to foster a critical thinking mindset in the design, development, and deployment of AI systems to minimize negative impacts.","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/RMF/govern-4/2012/01/16/teams-and-communications.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

		<link type="application/atom+xml" rel="alternate" href="http://localhost:4000/RMF/feed.xml" title="AI RMF Playbook" />

	</head>

	<body class="">
		<header>
			<div class="wrapper">
				<section class="top-bar">
                                        <nav>
	
	
		
                
                    
                    	 <button class="navbtn scale">
		    	 <a href="/RMF/" >HOME</a>
                         </button>
                    
                
	
	
		
                
                    
                    	 <button class="navbtn scale">
		    	 <a href="/RMF/govern/" >GOVERN</a>
                         </button>
                    
                
	
	
		
                
                    
                    	 <button class="navbtn scale">
		    	 <a href="/RMF/map/" >MAP</a>
                         </button>
                    
                
	
	
		
                
                     <a class="">MEASURE</a>
                
	
	
		
                
                     <a class="">MANAGE</a>
                
	
	
		
                
                    
                    	 <button class="navbtn scale">
		    	 <a href="/RMF/terms/" >TERMS</a>
                         </button>
                    
                
	
	
		
                
                    
       			 <button  class="navbtn scale"><a class="">&nbsp;</a></button>
        		 <button  class="navbtn scale"><a href="/RMF/about/">ABOUT</a></button>
                    
                
	
</nav>


				</section>
				<section class="hero_search">
					<h1>AI Risk Managment Framework Playbook</h1>
				</section>
			</div>

		</header>
		<section class="content">
			<div class="wrapper">
				<section class="tutorial">
	<section class="tutorial-content">
                
                <a href="/RMF/Govern" style="float:right">GOVERN</a>
                &nbsp&nbsp
	        <br>

                <h2 style="font-family: Arial;"> GOVERN 4.1 </h2>
              
                <h4 style="font-family: Arial;"> Organizational practices are in place to foster a critical thinking mindset in  the design, development, and deployment of AI systems to minimize negative impacts. </h4>

                <br>
		<div class="tutorial-main">
                        
   			   
<details>
  <summary><strong>What is this subcategory about?</strong></summary>
  <p><br />
A strong risk culture and accompanying practices can help organizations effectively triage the most critical risks. Organizations in some industries implement three (or more) “lines of defense,” where separate teams are held accountable for different aspects of the system lifecycle, such as development, risk management, and auditing.  While a traditional three-lines approach may be impractical for smaller organizations, leadership can commit to cultivating a strong risk culture through other means. For example, “effective challenge,” is a culture-based practice that encourages critical thinking and questioning of important design and implementation decisions by experts with the authority and stature to make such changes.</p>

  <p>Red-teaming is also another risk management approach. This practice consists of adversarial testing of AI systems under stress conditions to seek out failure modes or vulnerabilities in the system. Red-teams are composed of external experts or personnel who are independent from the AI design and development teams.</p>

</details>

<details>
  <summary><strong>How can organizations achieve the outcomes of this subcategory?</strong></summary>
  <ul>
    <li>Establish policies that require oversight functions (legal, compliance, risk management) from the outset of the system design process.</li>
    <li>Establish policies that promote effective challenge of AI system design, implementation, and deployment decisions, via mechanisms such as the three lines of defense, model audits, or red-teaming – to ensure that workplace risks such as groupthink do not take hold.</li>
    <li>Establish policies that incentivize general critical thinking and review at an organizational and procedural level.</li>
    <li>Establish whistleblower protections for insiders who report on perceived serious problems with AI systems.</li>
  </ul>

</details>

<details>
  <summary><strong>What are the transparency and documentation considerations?</strong></summary>
  <p><br />
Column G goes here.</p>

</details>

<details>
  <summary><strong>What are some informative references?</strong></summary>
  <p><br />
H.R. 2231, 116th Cong. (2019), https://www.congress.gov/bill/116th-congress/house-bill/2231/text</p>

  <p>BSA The Software Alliance (2021) Confronting Bias: BSA’s Framework to Build Trust in AI. https://www.bsa.org/reports/confronting-bias-bsas-framework-to-build-trust-in-ai</p>

  <p>David Wright, “Making Privacy Impact Assessments More Effective.” The Information Society 29, 2013, available at https://iapp.org/media/pdf/knowledge_center/Making_PIA__more_effective.pdf.</p>

  <p>E. Moss, E. Watkins, R. Singh, M. Elish, and J. Metcalf, “Assembling Accountability: Algorithmic Impact Assessment for the Public Interest.” [Online]. Available: https://datasociety.net/library/assembling-accountability-algorithmic-impact-assessment-for-the-public-interest/</p>

  <p>M. Kop, “AI Impact Assessment &amp; Code of Conduct,” Futurium, May 2019, https://futurium.ec.europa.eu/en/european-ai-alliance/best-practices/ai-impact-assessment-code-conduct.</p>

  <p>D. Reisman, J. Schultz, K. Crawford, and M. Whittaker, “Algorithmic Impact Assessments: A Practical Framework For Public Agency Accountability,” AI Now, Apr. 2018, https://ainowinstitute.org/aiareport2018.pdf.</p>

  <p>A. D. Selbst, “An Institutional View Of Algorithmic Impact Assessments,” Harvard Journal of Law &amp; Technology, vol. 35, no. 1, 2021</p>

  <p>Ada Lovelace Institute. 2022. Algorithmic Impact Assessment: A Case Study in Healthcare. Accessed July 14, 2022. https://www.adalovelaceinstitute.org/report/algorithmic-impact-assessment-case-study-healthcare/</p>

</details>

			

                </div>
                <br/>
                <br/>
                <a href="/RMF/govern-4/2012/01/16/teams-and-communications.html" class="back-to-top">Back to Top &uarr;</a>

	</section>
</section>




			</div>
		</section>

		<footer>
	<div class="wrapper">
		<p class="copyright" style="text-align:center;">&copy; AI RMF Playbook Released August 2022. </p>
	</div>
</footer>



 		<script src="/RMF/js/accordion.js"></script>

	</body>
</html>
