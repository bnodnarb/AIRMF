---
date: 2012-01-16
title: GOVERN 5.2
categories:
  - GOVERN-5
description: Processes are in place to equip and empower teams to make decisions about if and how to develop and deploy AI systems based on stakeholder considerations, and to define periodic reviews of impacts, including potential harm.
type: Govern
order_number: 2
---
{::options parse_block_html="true" /}


<details>
<summary markdown="span">**What is this subcategory about?**</summary>
<br>
Risk tolerance reflects the level and type of risk the organization will accept while conducting its mission and carrying out its strategy. Organizational leaders establish risk tolerances that others in the organization can follow via more fine-grained policies and procedures.

Organizations should accept that AI-related incidents can and will occur, focus on risk mitigation, and emphasize practical detection and mitigation. 

When risks arise, resources are allocated based on the assessed risk of a given AI system. Organizations should apply a risk tolerance approach in which higher risk systems receive larger allocations of risk management resources and lower risk systems receive less resources. Such allocation schemes are necessary to target limited risk management resources. Acknowledgement of risks also implies that some systems may be too risky to deploy given the organization’s risk tolerance, and organizational policies should address such scenarios.

</details>

<details>
<summary markdown="span">**How can organizations achieve the outcomes of this subcategory?**</summary>
* Explicitly acknowledge that AI systems, and the use of AI, present inherent costs and risks along with potential benefits.
* Define reasonable risk tolerances for AI systems informed by laws, regulation, best practices, or industry standards.
* Establish policies that define how to assign AI systems to established risk tolerance levels by combining system impact assessments with the likelihood that an impact occurs. Such assessment often entails some combination of:
    * Econometric evaluations of impacts and impact likelihoods to assess AI system risk.
    * Red-amber-green (RAG) scales for impact severity and likelihood to assess AI system risk.
    * Establishment of policies for allocating risk management resources along established risk tolerance levels, with higher-risk systems receive more risk management resources and oversight.
    * Establishment of policies for approval, conditional approval, and disapproval of the design, implementation, and deployment of AI systems.

</details>

<details>
<summary markdown="span">**What are the transparency and documentation considerations?**</summary>
<br>
Column G goes here.

</details>

<details>
<summary markdown="span">**What are some informative references?**</summary>
<br>
Bd. Governors Fed. Rsrv. Sys., Supervisory Guidance on Model Risk Management, SR Letter 11-7 (Apr. 4, 2011)

Off. Comptroller Currency, Comptroller’s Handbook: Model Risk Management (Aug. 2021), https://www.occ.gov/publications-and-resources/publications/comptrollers-handbook/files/model-risk-management/index-model-risk-management.html

The Office of the Comptroller of the Currency. Enterprise Risk Appetite Statement. (Nov. 20, 2019). Retrieved on July 12, 2022 from https://www.occ.treas.gov/publications-and-resources/publications/banker-education/files/pub-risk-appetite-statement.pdf

</details>
