---
date: 04-04-02
title: GOVERN 4.2
categories:
  - GOVERN-4
description: Organizational teams document the risks and impacts of the technology they design, develop, or deploy and communicate about these impacts more broadly.
type: Govern
order_number: 2
---
{::options parse_block_html="true" /}


<details>
<summary markdown="span">**What is this subcategory about?**</summary>
<br>
Impact assessments are an approach for driving responsible and ethical technology development practices. And, within a specific use case, these assessments can provide a high-level structure for organizations to frame risks of a given algorithm or deployment. Impact assessments can also serve as a mechanism for organizations to articulate risks and generate documentation for mitigation and oversight activities when harms do arise. 

Impact assessments should be applied at the beginning of a process but also iteratively and regularly since goals and outcomes can evolve over time. It is also important to consider conflicts of interest, or undue influence, related to the organizational team being assessed.

</details>

<details>
<summary markdown="span">**How can organizations achieve the outcomes of this subcategory?**</summary>
* Establish impact assessment policies and processes for AI systems used by the organization.
* Ensure impact assessment policies are appropriate to evaluate the potential negative impact of a system and how quickly a system changes, and that assessments are applied on a regular basis.
* Ensure impact assessments are utilized to inform broader assessments of AI system risk.

</details>

<details>
<summary markdown="span">**What are the transparency and documentation considerations?**</summary>
<br>
Column G goes here.

</details>

<details>
<summary markdown="span">**What are some informative references?**</summary>
<br>
Bd. Governors Fed. Rsrv. Sys., Supervisory Guidance on Model Risk Management, SR Letter 11-7 (Apr. 4, 2011)

Patrick Hall, Navdeep Gill, and Benjamin Cox, “Responsible Machine Learning,” O’Reilly Media, 2020, available at https://www.oreilly.com/library/view/responsible-machine-learning/9781492090878/

Off. Superintendent Fin. Inst. Canada, Enterprise-Wide Model Risk Management for Deposit-Taking
Institutions, E-23 (Sept. 2017).

GAO, “Artificial Intelligence: An Accountability Framework for Federal Agencies and Other Entities,” GAO@100 (GAO-21-519SP), June 2021, https://www.gao.gov/assets/gao-21-519sp.pdf.

Donald Sull, Stefano Turconi, and Charles Sull, “When It Comes to Culture, Does Your Company Walk the Talk?” MIT Sloan Mgmt. Rev., 2020, https://sloanreview.mit.edu/article/when-it-comes-to-culture-does-your-company-walk-the-talk.

Kathy Baxter, AI Ethics Maturity Model, Salesforce https://www.salesforceairesearch.com/static/ethics/EthicalAIMaturityModel.pdf

</details>
