<!DOCTYPE html>
<link rel="stylesheet" href="https://pages.nist.gov/nist-header-footer/css/nist-combined.css">
      <script src="https://pages.nist.gov/nist-header-footer/js/jquery-1.9.0.min.js" type="text/javascript" defer="defer"></script>
      <script src="https://pages.nist.gov/nist-header-footer/js/nist-header-footer.js" type="text/javascript" defer="defer"></script>


<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1">

		<link rel="stylesheet" href="/RMF/css/screen.css">
		<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Merriweather:400italic,400,300italic,300,700,700italic|Open+Sans:400italic,600italic,700italic,700,600,400|Inconsolata:400,700">

		

		<!-- Begin Jekyll SEO tag v2.4.0 -->
<title>MAP 1.7 | AI RMF Playbook</title>
<meta name="generator" content="Jekyll v3.9.2" />
<meta property="og:title" content="MAP 1.7" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="System requirements (e.g., “the system shall respect the privacy of its users”) are elicited and understood from stakeholders. Design decisions take socio-technical implications into account to address AI risk." />
<meta property="og:description" content="System requirements (e.g., “the system shall respect the privacy of its users”) are elicited and understood from stakeholders. Design decisions take socio-technical implications into account to address AI risk." />
<link rel="canonical" href="http://localhost:4000/RMF/map-1/2012/01/16/system-requirements.html" />
<meta property="og:url" content="http://localhost:4000/RMF/map-1/2012/01/16/system-requirements.html" />
<meta property="og:site_name" content="AI RMF Playbook" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2012-01-16T00:00:00+00:00" />
<script type="application/ld+json">
{"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/RMF/NISTlogo.png"}},"headline":"MAP 1.7","dateModified":"2012-01-16T00:00:00+00:00","datePublished":"2012-01-16T00:00:00+00:00","@type":"BlogPosting","url":"http://localhost:4000/RMF/map-1/2012/01/16/system-requirements.html","description":"System requirements (e.g., “the system shall respect the privacy of its users”) are elicited and understood from stakeholders. Design decisions take socio-technical implications into account to address AI risk.","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/RMF/map-1/2012/01/16/system-requirements.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

		<link type="application/atom+xml" rel="alternate" href="http://localhost:4000/RMF/feed.xml" title="AI RMF Playbook" />

	</head>

	<body class="">
		<header>
			<div class="wrapper">
				<section class="top-bar">
                                        <nav>
	
	
		
                
                    
                    	 <button class="navbtn scale">
		    	 <a href="/RMF/" >HOME</a>
                         </button>
                    
                
	
	
		
                
                    
                    	 <button class="navbtn scale">
		    	 <a href="/RMF/govern/" >GOVERN</a>
                         </button>
                    
                
	
	
		
                
                    
                    	 <button class="navbtn scale">
		    	 <a href="/RMF/map/" >MAP</a>
                         </button>
                    
                
	
	
		
                
                     <a class="">MEASURE</a>
                
	
	
		
                
                     <a class="">MANAGE</a>
                
	
	
		
                
                    
                    	 <button class="navbtn scale">
		    	 <a href="/RMF/terms/" >TERMS</a>
                         </button>
                    
                
	
	
		
                
                    
       			 <button  class="navbtn scale"><a class="">&nbsp;</a></button>
        		 <button  class="navbtn scale"><a href="/RMF/about/">ABOUT</a></button>
                    
                
	
</nav>


				</section>
				<section class="hero_search">
					<h1>AI Risk Managment Framework Playbook</h1>
				</section>
			</div>

		</header>
		<section class="content">
			<div class="wrapper">
				<section class="tutorial">
	<section class="tutorial-content">
                
                <a href="/RMF/Map" style="float:right">MAP</a>
                &nbsp&nbsp
	        <br>

                <h2 style="font-family: Arial;"> MAP 1.7 </h2>
              
                <h4 style="font-family: Arial;"> System requirements (e.g., “the system shall respect the privacy of its users”) are elicited and understood from stakeholders. Design decisions take socio-technical implications into account to address AI risk. </h4>

                <br>
		<div class="tutorial-main">
                        
   			   
<details>
  <summary><strong>What is this subcategory about?</strong></summary>
  <p><br />
AI system development requirements may outpace documentation processes for traditional software. When written requirements are unavailable or incomplete, AI actors may inadvertently overlook business and stakeholder needs, or over-rely on implicit human biases such as confirmation bias and groupthink. To mitigate the influence of these implicit factors, AI actors can seek input from, and develop transparent and actionable recourse mechanisms for, end-users and operators. Engaging external stakeholders in this process  integrates broader perspectives on socio-technical risk factors. Incorporating trustworthy characteristics early in the design phase should be a priority – instead of forcing a solution onto existing systems.</p>

</details>

<details>
  <summary><strong>How can organizations achieve the outcomes of this subcategory?</strong></summary>

  <ul>
    <li>Proactively incorporate trustworthy characteristics into system requirements.</li>
    <li>Consider risk factors related to Human-AI configurations and tasks.</li>
    <li>Analyze dependencies between contextual factors and system requirements. List impacts that may arise from not fully considering the importance of  trustworthiness characteristics in any decision making.</li>
    <li>Follow responsible design techniques in tasks such as software engineering, product management, and participatory engagement. Some examples for eliciting and documenting stakeholder requirements include product requirement documents (PRDs), user stories, user interaction/user experience (UI/UX) research, systems engineering, ethnography and related field methods.</li>
  </ul>

</details>

<details>
  <summary><strong>What are the transparency and documentation considerations?</strong></summary>
  <p><br />
<strong>Transparency Considerations – Key Questions: MAP 1.7</strong></p>
  <ul>
    <li>What type of information is accessible on the design, operations, and limitations of the AI system to external stakeholders, including end users, consumers, regulators, and individuals impacted by use of the AI system?</li>
    <li>To what extent is this information sufficient and appropriate to promote transparency? Promote transparency by enabling external stakeholders to access information on the design, operation, and limitations of the AI system.</li>
    <li>To what extent has relevant information been disclosed regarding the use of AI systems, such as (a) what the system is for, (b) what it is not for, (c) how it was designed, and (d) what its limitations are? (Documentation and external communication can offer a way for entities to provide transparency.)</li>
    <li>What metrics has the entity developed to measure performance of the AI system?</li>
    <li>What justifications, if any, has the entity provided for the assumptions, boundaries, and limitations of the AI system?</li>
  </ul>

  <p><strong>AI Transparency Resources: MAP 1.7</strong></p>
  <ul>
    <li>GAO-21-519SP: AI Accountability Framework for Federal Agencies &amp; Other Entities</li>
    <li>“Stakeholders in Explainable AI,” Sep. 2018, [Online]. Available: http://arxiv.org/abs/1810.00184</li>
    <li>“Including Insights from the Comptroller General’s Forum on the Oversight of Artificial Intelligence An Accountability Framework for Federal Agencies and Other Entities,” 2021</li>
    <li>“HIGH-LEVEL EXPERT GROUP ON ARTIFICIAL INTELLIGENCE SET UP BY THE EUROPEAN COMMISSION ETHICS GUIDELINES FOR TRUSTWORTHY AI.” [Online]. Available: https://ec.europa.eu/digital-</li>
  </ul>

</details>

<details>
  <summary><strong>What are some informative references?</strong></summary>
  <p><br />
National Academies of Sciences, Engineering, and Medicine 2022. Fostering Responsible Computing Research: Foundations and Practices. Washington, DC: The National Academies Press. https://doi.org/10.17226/26507.</p>

  <p>Amit K. Chopra, Fabiano Dalpiaz, F. Başak Aydemir, et al. 2014. Protos: Foundations for engineering innovative sociotechnical systems. In 2014 IEEE 22nd International Requirements Engineering Conference (RE) (2014), 53-62. DOI: https://doi.org/10.1109/RE.2014.6912247</p>

  <p>Andrew D. Selbst, Danah Boyd, Sorelle A. Friedler, et al. 2019. Fairness and Abstraction in Sociotechnical Systems. In Proceedings of the Conference on Fairness, Accountability, and Transparency (FAT* ‘19). Association for Computing Machinery, New York, NY, USA, 59–68. https://doi.org/10.1145/3287560.3287598</p>

  <p>Gordon Baxter and Ian Sommerville. 2011. Socio-technical systems: From design methods to systems engineering. Interacting with Computers, 23, 1 (Jan. 2011), 4–17. DOI: https://doi.org/10.1016/j.intcom.2010.07.003</p>

  <p>Roel Dobbe, Thomas Krendl Gilbert, and Yonatan Mintz. 2021. Hard choices in artificial intelligence. Artificial Intelligence 300 (14 July 2021), 103555, ISSN 0004-3702. DOI: https://doi.org/10.1016/j.artint.2021.103555</p>

  <p>Yilin Huang, Giacomo Poderi, Sanja Šćepanović, et al. 2019. Embedding Internet-of-Things in Large-Scale Socio-technical Systems: A Community-Oriented Design in Future Smart Grids. In The Internet of Things for Smart Urban Ecosystems (2019), 125-150. Springer, Cham. DOI: https://doi.org/10.1007/978-3-319-96550-5_6</p>

</details>

			

                </div>
                <br/>
                <br/>
                <a href="/RMF/map-1/2012/01/16/system-requirements.html" class="back-to-top">Back to Top &uarr;</a>

	</section>
</section>




			</div>
		</section>

		<footer>
	<div class="wrapper">
		<p class="copyright" style="text-align:center;">&copy; AI RMF Playbook Released August 2022. </p>
	</div>
</footer>



 		<script src="/RMF/js/accordion.js"></script>

	</body>
</html>
