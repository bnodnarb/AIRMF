---
date: 01-01-05
title: MAP 1.5
categories:
  - MAP-1
description: Organizational risk tolerances are determined. 
type: Map
order_number: 5
---

{::options parse_block_html="true" /}


<details>
<summary markdown="span">**What is this subcategory about?**</summary>
<br>
Risk tolerance reflects the level and type of risk the organization will accept while conducting its mission and carrying out its strategy. 

Deployment should not be pre-determined. Rather, it should result from a clearly defined process based on organizational risk tolerances. 
 
Go/no-go decisions should be incorporated throughout the AI system’s lifecycle. For systems deemed “higher risk,” such decisions should include approval from relevant technical or risk-focused executives. 

Go/no-go decisions related to AI system risks should take stakeholder feedback into account, but remain independent from stakeholders' vested financial or reputational interests

</details>

<details>
<summary markdown="span">**How can organizations achieve the outcomes of this subcategory?**</summary>

* Establish risk tolerance levels for AI systems and allocate the appropriate oversight resources to each level.
* Identify maximum allowable risk thresholds above which the system will not be deployed, within the contextual or application setting. 
* Attempts to use a system for “off-label” purposes should be approached with caution, especially in settings that organizations have deemed as high-risk. Document decisions, risk-related trade-offs, and system limitations.

</details>

<details>
<summary markdown="span">**What are the transparency and documentation considerations?**</summary>
<br>
**Transparency Considerations – Key Questions: MAP 1.5**
- What justifications, if any, has the entity provided for the assumptions, boundaries, and limitations of the AI system?
- How has the entity identified and mitigated potential impacts of bias in the data, including inequitable or discriminatory outcomes?
- To what extent are the established procedures effective in mitigating bias, inequity, and other concerns resulting from the system?

**AI Transparency Resources: MAP 1.5**
- GAO-21-519SP: AI Accountability Framework for Federal Agencies & Other Entities
- WEF Model AI Governance Framework Assessment 2020
- Companion to the WEF Model AI Governance Framework- 2020

</details>

<details>
<summary markdown="span">**What are some informative references?**</summary>    
<br>
Board of Governors of the Federal Reserve System. SR 11-7: Guidance on Model Risk Management. (April 4, 2011). Retrieved on July 6, 2022 from https://www.federalreserve.gov/supervisionreg/srletters/sr1107.htm

The Office of the Comptroller of the Currency. Enterprise Risk Appetite Statement. (Nov. 20, 2019). Retrieved on July 12, 2022 from https://www.occ.treas.gov/publications-and-resources/publications/banker-education/files/pub-risk-appetite-statement.pdf

</details>
