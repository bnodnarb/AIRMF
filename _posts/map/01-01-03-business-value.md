---
date: 01-01-03
title: MAP 1.3
categories:
  - MAP-1
description: The organization’s mission and relevant goals for the AI technology are understood and documented.
type: Map
order_number: 3
---
{::options parse_block_html="true" /} 


<details>
<summary markdown="span">**About**</summary>      
<br>
Defining and documenting the specific business purpose of an AI system in a broader context of societal values helps teams to evaluate risks and increases the clarity of “go/no-go” decisions about whether to deploy.

Trustworthy AI technologies may present a demonstrable business benefit beyond implicit or explicit costs, provide added value, and don't lead to wasted resources. Organizations can feel confident in performing risk avoidance if the implicit or explicit risks outweigh the advantages of AI systems,  and  not implementing an AI solution whose risks surpass potential benefits.

For example, making AI systems more equitable can result in better managed risk, and can help enhance consideration of the business value of making inclusively designed, accessible and more equitable AI systems.

</details>

<details>
<summary markdown="span">**Suggested Actions**</summary>

- Build transparent practices into AI system development processes.
- Review the documented system purpose from a socio-technical perspective and in consideration of societal values.
- Determine possible misalignment between societal values and stated organizational principles and code of ethics.
- Flag latent incentives that may contribute to negative impacts.
- Evaluate AI system purpose in consideration of potential risks, societal values, and stated organizational principles.

</details>

<details>
<summary markdown="span">**Transparency and Documentation**</summary>  
<br>
**Organizations can document the following:**
- How does the AI system help the entity meet its goals and objectives?
- How do the technical specifications and requirements align with the AI system’s goals and objectives?
- To what extent is the output appropriate for the operational context?

**AI Transparency Resources:**
- Assessment List for Trustworthy AI (ALTAI) - The High-Level Expert Group on AI – 2019, [LINK](https://altai.insight-centre.org/), [URL](https://digital-strategy.ec.europa.eu/en/library/assessment-list-trustworthy-artificial-intelligence-altai-self-assessment).
- Including Insights from the Comptroller General’s Forum on the Oversight of Artificial Intelligence An Accountability Framework for Federal Agencies and Other Entities, 2021, [URL](https://www.gao.gov/products/gao-21-519sp), [PDF](https://www.gao.gov/assets/gao-21-519sp-highlights.pdf).
 
</details>

<details>
<summary markdown="span">**References**</summary>      
<br>
M.S. Ackerman (2000). The Intellectual Challenge of CSCW: The Gap Between Social Requirements and Technical Feasibility. Human–Computer Interaction, 15, 179 - 203. [URL](https://socialworldsresearch.org/sites/default/files/hci.final_.pdf)

McKane Andrus, Sarah Dean, Thomas Gilbert,  Nathan Lambert, Tom Zick (2021). AI Development for the Public Interest: From Abstraction Traps to Sociotechnical Risks. [URL](https://arxiv.org/pdf/2102.04255.pdf)

Abeba Birhane, Pratyusha Kalluri, Dallas Card, et al. 2022. The Values Encoded in Machine Learning Research. arXiv:2106.15590. [URL](https://arxiv.org/abs/2106.15590)

Board of Governors of the Federal Reserve System. SR 11-7: Guidance on Model Risk Management. (April 4, 2011). [URL](https://www.federalreserve.gov/supervisionreg/srletters/sr1107.htm)

Iason Gabriel, Artificial Intelligence, Values, and Alignment. Minds & Machines 30, 411–437 (2020). [URL](https://doi.org/10.1007/s11023-020-09539-2)

PEAT “Business Case for Equitable AI”. [URL](https://www.peatworks.org/ai-disability-inclusion-toolkit/business-case-for-equitable-ai/) 

</details>
