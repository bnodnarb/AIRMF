<!DOCTYPE html>
<link rel="stylesheet" href="https://pages.nist.gov/nist-header-footer/css/nist-combined.css">
      <script src="https://pages.nist.gov/nist-header-footer/js/jquery-1.9.0.min.js" type="text/javascript" defer="defer"></script>
      <script src="https://pages.nist.gov/nist-header-footer/js/nist-header-footer.js" type="text/javascript" defer="defer"></script>


<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1">

		<link rel="stylesheet" href="/RMF/css/screen.css">
		<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Merriweather:400italic,400,300italic,300,700,700italic|Open+Sans:400italic,600italic,700italic,700,600,400|Inconsolata:400,700">

		

		<!-- Begin Jekyll SEO tag v2.4.0 -->
<title>MAP 3.1 | AI RMF Playbook</title>
<meta name="generator" content="Jekyll v3.9.2" />
<meta property="og:title" content="MAP 3.1" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Benefits of intended system behavior are examined and documented." />
<meta property="og:description" content="Benefits of intended system behavior are examined and documented." />
<link rel="canonical" href="http://localhost:4000/RMF/map-3/2012/01/16/system-benefits.html" />
<meta property="og:url" content="http://localhost:4000/RMF/map-3/2012/01/16/system-benefits.html" />
<meta property="og:site_name" content="AI RMF Playbook" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2012-01-16T00:00:00+00:00" />
<script type="application/ld+json">
{"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/RMF/NISTlogo.png"}},"headline":"MAP 3.1","dateModified":"2012-01-16T00:00:00+00:00","datePublished":"2012-01-16T00:00:00+00:00","@type":"BlogPosting","url":"http://localhost:4000/RMF/map-3/2012/01/16/system-benefits.html","description":"Benefits of intended system behavior are examined and documented.","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/RMF/map-3/2012/01/16/system-benefits.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

		<link type="application/atom+xml" rel="alternate" href="http://localhost:4000/RMF/feed.xml" title="AI RMF Playbook" />

	</head>

	<body class="">
		<header>
			<div class="wrapper">
				<section class="top-bar">
                                        <nav>
	
	
		
                
                    
                    	 <button class="navbtn scale">
		    	 <a href="/RMF/" >HOME</a>
                         </button>
                    
                
	
	
		
                
                    
                    	 <button class="navbtn scale">
		    	 <a href="/RMF/govern/" >GOVERN</a>
                         </button>
                    
                
	
	
		
                
                    
                    	 <button class="navbtn scale">
		    	 <a href="/RMF/map/" >MAP</a>
                         </button>
                    
                
	
	
		
                
                     <a class="">MEASURE</a>
                
	
	
		
                
                     <a class="">MANAGE</a>
                
	
	
		
                
                    
                    	 <button class="navbtn scale">
		    	 <a href="/RMF/terms/" >TERMS</a>
                         </button>
                    
                
	
	
		
                
                    
       			 <button  class="navbtn scale"><a class="">&nbsp;</a></button>
        		 <button  class="navbtn scale"><a href="/RMF/about/">ABOUT</a></button>
                    
                
	
</nav>


				</section>
				<section class="hero_search">
					<h1>AI Risk Managment Framework Playbook</h1>
				</section>
			</div>

		</header>
		<section class="content">
			<div class="wrapper">
				<section class="tutorial">
	<section class="tutorial-content">
                
                <a href="/RMF/Map" style="float:right">MAP</a>
                &nbsp&nbsp
	        <br>

                <h2 style="font-family: Arial;"> MAP 3.1 </h2>
              
                <h4 style="font-family: Arial;"> Benefits of intended system behavior are examined and documented. </h4>

                <br>
		<div class="tutorial-main">
                        
   			   
<details>
  <summary><strong>What is this subcategory about?</strong></summary>
  <p><br />
AI system benefits should counterbalance the inherent risks and implicit and explicit costs. To identify system benefits, organizations should define and document system purpose and utility, along with foreseeable costs, risks, and negative impacts. Credible justification for anticipated benefits beyond the status quo should be clarified and documented.</p>

</details>

<details>
  <summary><strong>How can organizations achieve the outcomes of this subcategory?</strong></summary>

  <ul>
    <li>Utilize participatory approaches and engage with system end users to evaluate system efficacy and interpretability of AI task output.</li>
    <li>Incorporate stakeholder feedback about perceived system benefits beyond the status quo.</li>
    <li>Align system requirements with intended purpose and document decisions.</li>
    <li>Perform context analysis related to time frame, safety concerns, geographic area, physical environment, ecosystems, social environment, and cultural norms within the intended setting (or conditions that closely approximate the intended setting).</li>
  </ul>

</details>

<details>
  <summary><strong>What are the transparency and documentation considerations?</strong></summary>
  <p><br />
<strong>Transparency Considerations – Key Questions: MAP 3.1</strong></p>
  <ul>
    <li>Did you communicate the benefits of the AI system to users?</li>
    <li>Did you provide appropriate training material and disclaimers to users on how to adequately use the AI system?</li>
    <li>Did your organization implement a risk management system to address risks involved in deploying the identified AI solution (e.g. personnel risk or changes to commercial objectives)?</li>
  </ul>

  <p><strong>AI Transparency Resources: MAP 3.1</strong></p>
  <ul>
    <li>Intel.gov: AI Ethics Framework for Intelligence Community  - 2020</li>
    <li>GAO-21-519SP: AI Accountability Framework for Federal Agencies &amp; Other Entities</li>
    <li>Assessment List for Trustworthy AI (ALTAI) - The High-Level Expert Group on AI – 2019</li>
  </ul>

</details>

<details>
  <summary><strong>What are some informative references?</strong></summary>
  <p><br />
Roel Dobbe, Thomas Krendl Gilbert, and Yonatan Mintz. 2021. Hard choices in artificial intelligence. Artificial Intelligence 300 (14 July 2021), 103555, ISSN 0004-3702. DOI: https://doi.org/10.1016/j.artint.2021.103555</p>

  <p>Samir Passi and Solon Barocas. 2019. Problem Formulation and Fairness. In Proceedings of the Conference on Fairness, Accountability, and Transparency (FAT* ‘19). Association for Computing Machinery, New York, NY, USA, 39–48. https://doi.org/10.1145/3287560.3287567</p>

</details>

			

                </div>
                <br/>
                <br/>
                <a href="/RMF/map-3/2012/01/16/system-benefits.html" class="back-to-top">Back to Top &uarr;</a>

	</section>
</section>




			</div>
		</section>

		<footer>
	<div class="wrapper">
		<p class="copyright" style="text-align:center;">&copy; AI RMF Playbook Released August 2022. </p>
	</div>
</footer>



 		<script src="/RMF/js/accordion.js"></script>

	</body>
</html>
