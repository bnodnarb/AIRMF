---
date: 01-05-03
title: MAP 5.3
categories:
  - MAP-5
description: Assessments of benefits vs impacts are based on analyses of impact, magnitude, and likelihood of risk.
type: Map
order_number: 3
---

{::options parse_block_html="true" /}


<details>
<summary markdown="span">**About**</summary>
<br>
The final output of the Map function is the go/no-go decision for deploying the AI system. This decision should take into account the risks mapped from previous steps and the organizational capacity for their management. 

Risk mapping should also list system benefits beyond the status quo. Go/no-go decisions to deploy may be made by an independent third-party or organizational management. For higher risk systems, it is often appropriate – and may well be critical – for technical or risk executives to be involved in the approval of go/no-go decisions to deploy. 

The decision to deploy should not be made by AI actors carrying out design and development functions, whose objective judgment may be hindered by the incentive to deploy systems in which they were closely involved.

</details>

<details>
<summary markdown="span">**Actions**</summary>

* Review and examine documentation, including system purpose and benefits, and mapped potential impacts with associated likelihoods. 
* Document the system's estimated risk.
* Make a go/no-go determination based on magnitude, and likelihood of impact. Do not deploy (no-go) or decommission the system if estimated risk surpasses organizational tolerances or thresholds. If a decision is made to proceed with deployment, assign the system to an appropriate risk tolerance and align oversight resources with the assessed risk.

</details>

<details>
<summary markdown="span">**Transparency and Documentation**</summary>
<br>
**Transparency Considerations – Key Questions: MAP 5.3**
- To what extent do these policies foster public trust and confidence in the use of the AI system?
- What type of information is accessible on the design, operations, and limitations of the AI system to external stakeholders, including end users, consumers, regulators, and individuals impacted by use of the AI system?
- How has the entity identified and mitigated potential impacts of bias in the data, including inequitable or discriminatory outcomes?

**AI Transparency Resources: MAP 5.3**
- Datasheets for Datasets
- GAO-21-519SP: AI Accountability Framework for Federal Agencies & Other Entities
- “AI policies and initiatives,” in Artificial Intelligence in Society, OECD, 2019
- Intel.gov: AI Ethics Framework for Intelligence Community  - 2020
- Assessment List for Trustworthy AI (ALTAI) - The High-Level Expert Group on AI - 2019

</details>

<details>
<summary markdown="span">**References**</summary>
<br>
Board of Governors of the Federal Reserve System. SR 11-7: Guidance on Model Risk Management. (April 4, 2011). [URL](https://www.federalreserve.gov/supervisionreg/srletters/sr1107.htm)

Elisa Jillson. 2021. Aiming for truth, fairness, and equity in your company’s use of AI (April 19, 2021). [URL](https://www.ftc.gov/business-guidance/blog/2021/04/aiming-truth-fairness-equity-your-companys-use-ai)

Sarah Spiekermann and Till Winkler. 2020. Value-based Engineering for Ethics by Design. arXiv:2004.13676. [URL](https://arxiv.org/abs/2004.13676)

Sri Krishnamurthy. Quantifying Model Risk: Issues and approaches to measure and assess model risk when building quant models. QuantUniversity, Charlestown, MA. [URL](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.986.5412&rep=rep1&type=pdf)

