---
date: 03-03-02
title: MANAGE 3.2
categories:
  - MANAGE-3
description: Pre-trained models which are used for development are monitored as part of AI system regular  monitoring and maintenance.  
type: Manage
order_number: 2
---
{::options parse_block_html="true" /} 


<details>
<summary markdown="span"><span style="color:#FBFAF5">**About**</span></summary>      
<br>
A common approach in AI development is transfer learning, whereby an existing pre-trained model is adapted for use in a different, but related application. AI actors in development tasks often use pre-trained models from third-party entities for tasks such as image classification, language prediction, and entity recognition, because the resources to build such models may not be readily available to most organizations. Pre-trained models are typically trained to address various classification or prediction problems, using exceedingly large datasets and computationally intensive resources. The use of pre-trained models can make it difficult to anticipate negative system outcomes or impacts. Lack of documentation or transparency tools increases the difficulty and general complexity when deploying pre-trained models and hinders root cause analyses. 
</details>

<details>
<summary markdown="span"><span style="color:#FBFAF5">**Suggested Actions**</span></summary>

- Identify pre-trained models within AI system inventory for risk tracking.
- Establish processes to independently and continually monitor performance and trustworthiness  of pre-trained models, and as part of third-party risk tracking. 
- Monitor performance and trustworthiness of AI system components connected to pre-trained models, and as part of third-party risk tracking.
- Identify, document and remediate risks arising from AI system components and pre-trained models per organizational risk management procedures, and as part of third-party risk tracking.
- Decommission AI system components and pre-trained models which exceed risk tolerances, and as part of third-party risk tracking.

</details>

<details>
<summary markdown="span"><span style="color:#FBFAF5">**Transparency and Documentation**</span></summary>
<br>
**Organizations can document the following:**

- How has the entity documented the AI system’s data provenance, including sources, origins, transformations, augmentations, labels, dependencies, constraints, and metadata?
- Does this dataset collection/processing procedure achieve the motivation for creating the dataset stated in the first section of this datasheet?
- How does the entity ensure that the data collected are adequate, relevant, and not excessive in relation to the intended purpose?
- If the dataset becomes obsolete how will this be communicated?

**AI Transparency Resources:**

- Artificial Intelligence Ethics Framework For The Intelligence Community. [URL](https://www.intelligence.gov/artificial-intelligence-ethics-framework-for-the-intelligence-community)
- WEF - Companion to the Model AI Governance Framework – Implementation and Self-Assessment Guide for Organizations. [URL](https://www.pdpc.gov.sg/-/media/files/pdpc/pdf-files/resource-for-organisation/ai/sgisago.ashx)
- Datasheets for Datasets. [URL](https://arxiv.org/abs/1803.09010)

</details>

<details>
<summary markdown="span"><span style="color:#FBFAF5">**References**</span></summary>      
<br>
Larysa Visengeriyeva et al. “Awesome MLOps,“ GitHub. Accessed January 9, 2023. [URL](https://github.com/visenger)  


</details>
