---
date: 04-06-01
title: GOVERN 6.1
categories:
  - GOVERN-6
description: Policies and procedures are in place that address risks associated with third-party entities. 
type: Govern
order_number: 1
---
{::options parse_block_html="true" /}


<details>
<summary markdown="span">**About**</summary>
<br>
Organizations usually engage multiple third parties for external expertise, data, software packages (both open source and commercial), and software and hardware platforms across the AI lifecycle.  

The need to rely on external resources or expertise may heighten existing challenges in an already complex undertaking, increasing the difficulty of risk management efforts. 

Organizational approaches to managing third-party risk should be tailored to the resources, risk profile, and use case for each system. Organizations should strive to apply governance approaches to third-party AI system and data as they would for internal resources — including open source software, publicly available data, and commercially available models.

</details>

<details>
<summary markdown="span">**Actions**</summary>
<br>
* Collaboratively establish policies that address third-party AI systems and data.
* Establish policies related to:
    * Transparency into third-party system functions, including knowledge about training data, training and inference algorithms, and assumptions and limitations.
    * Thorough testing of third-party AI systems.
    * Requirements for clear and complete instructions for third-party system usage.

</details>

<details>
<summary markdown="span">**Transparency and Documentation**</summary>
<br>
**Organizations can document the following:**
- Did you establish mechanisms that facilitate the AI system’s auditability (e.g. traceability of the development process, the sourcing of training data and the logging of the AI system’s processes, outcomes, positive and negative impact)?
- If a third party created the AI, how will you ensure a level of explainability or interpretability?
- Did you ensure that the AI system can be audited by independent third parties?
- Did you establish a process for third parties (e.g. suppliers, end-users, subjects, distributors/vendors or workers) to report potential vulnerabilities, risks or biases in the AI system?
- To what extent does the plan specifically address risks associated with acquisition, procurement of packaged software from vendors, cybersecurity controls, computational infrastructure, data, data science, deployment mechanics, and system failure?

**AI Transparency Resources:**
- [GAO-21-519SP: AI Accountability Framework for Federal Agencies & Other Entities]()
- [Intel.gov: AI Ethics Framework for Intelligence Community  - 2020](https://www.intelligence.gov/artificial-intelligence-ethics-framework-for-the-intelligence-community)
- [WEF Model AI Governance Framework Assessment 2020](https://www.pdpc.gov.sg/-/media/Files/PDPC/PDF-Files/Resource-for-Organisation/AI/SGModelAIGovFramework2.pdf)
- [WEF Companion to the Model AI Governance Framework- 2020](https://www.pdpc.gov.sg/-/media/Files/PDPC/PDF-Files/Resource-for-Organisation/AI/SGIsago.pdf)
- “AI policies and initiatives,” in Artificial Intelligence in Society, OECD, 2019
- Assessment List for Trustworthy AI (ALTAI) - The High-Level Expert Group on AI - 2019


</details>

<details>
<summary markdown="span">**References**</summary>
<br>
Bd. Governors Fed. Rsrv. Sys., Supervisory Guidance on Model Risk Management, SR Letter 11-7 (Apr. 4, 2011)

“Proposed Interagency Guidance on Third-Party Relationships: Risk Management,” 2021. [URL](https://www.occ.gov/news-issuances/news-releases/2021/nr-occ-2021-74a.pdf)

Off. Comptroller Currency, Comptroller’s Handbook: Model Risk Management (Aug. 2021). [URL](https://www.occ.gov/publications-and-resources/publications/comptrollers-handbook/files/model-risk-management/index-model-risk-management.html)

</details>
