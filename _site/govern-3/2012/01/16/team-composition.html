<!DOCTYPE html>
<link rel="stylesheet" href="https://pages.nist.gov/nist-header-footer/css/nist-combined.css">
      <script src="https://pages.nist.gov/nist-header-footer/js/jquery-1.9.0.min.js" type="text/javascript" defer="defer"></script>
      <script src="https://pages.nist.gov/nist-header-footer/js/nist-header-footer.js" type="text/javascript" defer="defer"></script>


<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1">

		<link rel="stylesheet" href="/RMF/css/screen.css">
		<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Merriweather:400italic,400,300italic,300,700,700italic|Open+Sans:400italic,600italic,700italic,700,600,400|Inconsolata:400,700">

		

		<!-- Begin Jekyll SEO tag v2.4.0 -->
<title>GOVERN 3.1 | AI RMF Playbook</title>
<meta name="generator" content="Jekyll v3.9.2" />
<meta property="og:title" content="GOVERN 3.1" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Decision making related to mapping, measuring, and managing AI risks throughout the lifecycle is informed by a demographically and disciplinarily diverse team, including internal and external personnel. Specifically, teams that are directly engaged with identifying design considerations and risks include a diversity of experience, expertise, and backgrounds to ensure AI systems meet requirements beyond a narrow subset of users." />
<meta property="og:description" content="Decision making related to mapping, measuring, and managing AI risks throughout the lifecycle is informed by a demographically and disciplinarily diverse team, including internal and external personnel. Specifically, teams that are directly engaged with identifying design considerations and risks include a diversity of experience, expertise, and backgrounds to ensure AI systems meet requirements beyond a narrow subset of users." />
<link rel="canonical" href="http://localhost:4000/RMF/govern-3/2012/01/16/team-composition.html" />
<meta property="og:url" content="http://localhost:4000/RMF/govern-3/2012/01/16/team-composition.html" />
<meta property="og:site_name" content="AI RMF Playbook" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2012-01-16T00:00:00+00:00" />
<script type="application/ld+json">
{"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/RMF/NISTlogo.png"}},"headline":"GOVERN 3.1","dateModified":"2012-01-16T00:00:00+00:00","datePublished":"2012-01-16T00:00:00+00:00","@type":"BlogPosting","url":"http://localhost:4000/RMF/govern-3/2012/01/16/team-composition.html","description":"Decision making related to mapping, measuring, and managing AI risks throughout the lifecycle is informed by a demographically and disciplinarily diverse team, including internal and external personnel. Specifically, teams that are directly engaged with identifying design considerations and risks include a diversity of experience, expertise, and backgrounds to ensure AI systems meet requirements beyond a narrow subset of users.","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/RMF/govern-3/2012/01/16/team-composition.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

		<link type="application/atom+xml" rel="alternate" href="http://localhost:4000/RMF/feed.xml" title="AI RMF Playbook" />

	</head>

	<body class="">
		<header>
			<div class="wrapper">
				<section class="top-bar">
                                        <nav>
	
	
		
                
                    
                    	 <button class="navbtn scale">
		    	 <a href="/RMF/" >HOME</a>
                         </button>
                    
                
	
	
		
                
                    
                    	 <button class="navbtn scale">
		    	 <a href="/RMF/govern/" >GOVERN</a>
                         </button>
                    
                
	
	
		
                
                    
                    	 <button class="navbtn scale">
		    	 <a href="/RMF/map/" >MAP</a>
                         </button>
                    
                
	
	
		
                
                     <a class="">MEASURE</a>
                
	
	
		
                
                     <a class="">MANAGE</a>
                
	
	
		
                
                    
                    	 <button class="navbtn scale">
		    	 <a href="/RMF/terms/" >TERMS</a>
                         </button>
                    
                
	
	
		
                
                    
       			 <button  class="navbtn scale"><a class="">&nbsp;</a></button>
        		 <button  class="navbtn scale"><a href="/RMF/about/">ABOUT</a></button>
                    
                
	
</nav>


				</section>
				<section class="hero_search">
					<h1>AI Risk Managment Framework Playbook</h1>
				</section>
			</div>

		</header>
		<section class="content">
			<div class="wrapper">
				<section class="tutorial">
	<section class="tutorial-content">
                
                <a href="/RMF/govern.html" style="float:right">GOVERN</a>
                &nbsp&nbsp
	        <br>

                <h2 style="font-family: Arial;"> GOVERN 3.1 </h2>
              
                <h4 style="font-family: Arial;"> Decision making related to mapping, measuring, and managing AI risks throughout the lifecycle is informed by a demographically and disciplinarily diverse team, including internal and external personnel. Specifically, teams that are directly engaged with identifying design considerations and risks include a diversity of experience, expertise, and backgrounds to ensure AI systems meet requirements beyond a narrow subset of users. </h4>

                <br>
		<div class="tutorial-main">
                        
   			   
<details>
  <summary><strong>What is this subcategory about?</strong></summary>
  <p><br />
To enhance organizational capacity for anticipating risks, AI actors should reflect a diversity of experience, expertise and backgrounds. Consultation with external personnel may be necessary when internal teams lack a diverse range of lived experiences or disciplinary expertise.</p>

  <p>Research has shown that technicians with the same demographic backgrounds make similar misjudgments. To extend the benefits of diversity, equity, and inclusion to both the users and developers of it is recommended that teams are composed of a diverse group of individuals who reflect a range of backgrounds, perspectives and expertise. A diverse team enables more open sharing of ideas and assumptions about the AI system purpose and can help organizations understand:</p>
  <ul>
    <li>How the AI system may impact a wide variety of users;</li>
    <li>How users might interact with the system;</li>
    <li>Effectiveness of troubleshooting efforts, such as feedback channels; 
How the system may create impacts beyond the intended users of the system.</li>
  </ul>

  <p>Without commitment from senior leadership, beneficial aspects of team diversity and inclusion can be overridden by unstated organizational incentives that inadvertently conflict with the broader values of a diverse workforce.</p>

</details>

<details>
  <summary><strong>How can organizations achieve the outcomes of this subcategory?</strong></summary>
  <p><br />
Organizational management can:</p>
  <ul>
    <li>Define policies and hiring practices at the outset that promote interdisciplinary roles, competencies, skills, and capacity for AI efforts.</li>
    <li>Define policies and hiring practices that lead to demographic and domain expertise diversity; empower staff with necessary resources and support, and facilitate the contribution of staff feedback and concerns without fear of reprisal.</li>
    <li>Establish policies that facilitate inclusivity and the integration of new insights into existing practice.</li>
    <li>Seek external expertise to supplement organizational diversity, equity, inclusion, and accessibility where internal expertise is lacking.</li>
  </ul>

</details>

<details>
  <summary><strong>What are the transparency and documentation considerations?</strong></summary>
  <p><br />
Column G goes here.</p>

</details>

<details>
  <summary><strong>What are some informative references?</strong></summary>
  <p><br />
Dylan Walsh, “How can human-centered AI fight bias in machines and people?” MIT Sloan Mgmt. Rev., 2021, available at https://mitsloan.mit.edu/ideas-made-to-matter/howcan-human-centered-ai-fight-bias-machine.</p>

  <p>Michael Li, “To Build Less-Biased AI, Hire a More Diverse Team,” Harvard Bus. Rev., 2020, available at https://hbr.org/2020/10/to-build-less-biased-ai-hire-a-more-diverse-team.</p>

  <p>Bo Cowgill et al., “Biased Programmers? Or Biased Data? A Field Experiment in Operationalizing</p>

  <p>AI Ethics,” 2020, available at https://arxiv.org/pdf/2012.02394.pdf.</p>

  <p>N. Ellemers and F. Rink, “Diversity in work groups,” Current opinion in psychology, vol. 11, pp. 49–53, 2016.</p>

  <p>K. Talke, S. Salomo, and A. Kock, “Top management team diversity and strategic innovation orientation: The relationship and consequences for innovativeness and performance,” Journal of Product Innovation Management, vol. 28, pp. 819–832, 2011.</p>

  <p>S. M. West, M. Whittaker, and K. Crawford, “Discriminating Systems: Gender, Race, and Power in AI,” AI Now Institute, Tech. Rep., 2019. [Online]. Available: https://ainowinstitute.org/discriminatingsystems.pdf</p>

  <p>S. Fazelpour, M. De-Arteaga, Diversity in sociotechnical machine learning systems. Big Data &amp; Society. January 2022. doi:10.1177/20539517221082027</p>

  <p>Cummings, M.L., and Li, S. 2021a. Sources of subjectivity in machine learning models. ACM Journal of Data and Information Quality, 13(2), 1–9</p>

</details>

			

                </div>
                <br/>
                <br/>
                <a href="/RMF/govern-3/2012/01/16/team-composition.html" class="back-to-top">Back to Top &uarr;</a>

	</section>
</section>




			</div>
		</section>

		<footer>
	<div class="wrapper">
		<p class="copyright" style="text-align:center;">&copy; AI RMF Playbook Released August 2022. </p>
	</div>
</footer>



 		<script src="/RMF/js/accordion.js"></script>

	</body>
</html>
