---
date: 01-05-02
title: MAP 5.2
categories:
  - MAP-5
description: Likelihood and magnitude of each identified impact based on expected use, past uses of AI systems in similar contexts, public incident reports, stakeholder feedback, or other data are identified and documented.
type: Map
order_number: 2
---

{::options parse_block_html="true" /}


<details>
<summary markdown="span">**About**</summary>
<br>
The likelihood of AI system impacts identified in Map 5.1 should be evaluated. Potential impacts should be documented and triaged. 

Likelihood estimates may then be assessed and judged for go/no-go decisions about deploying an AI system. If an organization decides to proceed with deploying the system, the likelihood estimate can be used to assign oversight resources appropriate for the  risk level.

</details>

<details>
<summary markdown="span">**Actions**</summary>

* Establish assessment scales for measuring AI system impact. Scales may be qualitative, such as red-amber-green (RAG), or may entail simulations or econometric approaches. Document and apply scales uniformly across the organization’s AI portfolio. 
* Apply impact assessments regularly at key stages in the AI lifecycle, connected to system impacts and frequency of system updates. 
* Assess system benefits and negative impacts in relation to trustworthy characteristics.

</details>

<details>
<summary markdown="span">**Transparency and Documentation**</summary>
<br>
**Organizations can document the following:**
- Which population(s) does the AI system impact?
- What assessments has the entity conducted on data security and privacy impacts associated with the AI system?
- Can the AI system be audited by independent third parties?

**AI Transparency Resources:**
- Datasheets for Datasets
- GAO-21-519SP: AI Accountability Framework for Federal Agencies & Other Entities
- “AI policies and initiatives,” in Artificial Intelligence in Society, OECD, 2019
- Intel.gov: AI Ethics Framework for Intelligence Community  - 2020
- Assessment List for Trustworthy AI (ALTAI) - The High-Level Expert Group on AI - 2019

</details>

<details>
<summary markdown="span">**References**</summary>
<br>
Emilio Gómez-González and Emilia Gómez. 2020. Artificial intelligence in medicine and healthcare. Joint Research Centre (European Commission). [URL](https://op.europa.eu/en/publication-detail/-/publication/b4b5db47-94c0-11ea-aac4-01aa75ed71a1/language-en)

Artificial Intelligence Incident Database. 2022. [URL](https://incidentdatabase.ai/?lang=en)

Anthony M. Barrett, Dan Hendrycks, Jessica Newman and Brandie Nonnecke. “Actionable Guidance for High-Consequence AI Risk Management: Towards Standards Addressing AI Catastrophic Risks". ArXiv abs/2206.08966 (2022) [URL](https://arxiv.org/abs/2206.08966)
</details>
