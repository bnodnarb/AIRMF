---
date: 2012-01-16
title: GOVERN 1.3
categories:
  - GOVERN-1
description: Ongoing monitoring and periodic review of the risk management process and its outcomes are planned, with organizational roles and responsibilities clearly defined.
type: Govern
order_number: 3
---
{::options parse_block_html="true" /}


<details>
<summary markdown="span">**What is this subcategory about?**</summary>
<br>
Clear policies and procedures are necessary to communicate roles and responsibilities for the Map, Measure and Manage functions across the AI lifecycle.

Standardized documentation can operationalize how organizational AI risk management processes are implemented and recorded. Systematizing documentation can also enhance accountability efforts. By adding their contact information to a work product document, AI actors can improve communication, increase ownership of work products, and potentially enhance consideration of product quality. Documentation may generate downstream benefits related to improved system replicability and robustness. Proper documentation storage and access procedures allow for quick retrieval of critical information during a negative incident.

</details>

<details>
<summary markdown="span">**How can organizations achieve the outcomes of this subcategory?**</summary>
* Establish and regularly review documentation policies that address information related to:
    * AI actor contact information
    * Business justification
    * Scope and usage
    * Assumptions and limitations
    * Description of training data
    * Algorithmic methodology
    * Evaluated alternative approaches
    * Description of output data
    * Testing and validation results
    * Down- and up-stream dependencies
    * Plans for deployment, monitoring, and change management
    * Stakeholder engagement plans
* Verify documentation policies for AI systems are standardized across the organization and up to date.
* Establish policies for a model documentation inventory system and regularly review its completeness, usability, and efficacy.
* Establish mechanisms to regularly review the efficacy of risk management processes.
* Identify AI actors responsible for evaluating efficacy of risk management processes and approaches, and for course-correction based on results.


</details>

<details>
<summary markdown="span">**What are the transparency and documentation considerations?**</summary>
<br>
Column G goes here.

</details>

<details>
<summary markdown="span">**What are some informative references?**</summary>
<br>
Bd. Governors Fed. Rsrv. Sys., Supervisory Guidance on Model Risk Management, SR Letter 11-7 (Apr. 4, 2011).

Off. Comptroller Currency, Comptroller’s Handbook: Model Risk Management (Aug. 2021), https://ww w.occ.gov/publications-and-resources/publications/comptrollers-handbook/files/model-risk-management /index-model-risk-management.html.

Margaret Mitchell et al., “Model Cards for Model Reporting." Proceedings of 2019 FATML Conference, available at https://arxiv.org/pdf/1810.03993.pdf.

Timnit Gebru et al., “Datasheets for Datasets,” Communications of the ACM 64, No. 12, 2021, available at https://arxiv.org/pdf/1803.09010.pdf.

Bender, E. M., Friedman, B. & McMillan-Major, A.,  (2022). A Guide for Writing Data Statements for Natural Language Processing. University of Washington.  Accessed July 14, 2022. .https://techpolicylab.uw.edu/wp-content/uploads/2021/11/Data_Statements_Guide_V2.pdf

M. Arnold, R. K. E. Bellamy, M. Hind, et al. FactSheets: Increasing trust in AI services through supplier's declarations of conformity. IBM Journal of Research and Development 63, 4/5 (July-September 2019), 6:1-6:13. https://ieeexplore.ieee.org/document/8843893

John Richards, David Piorkowski, Michael Hind, et al. A Human-Centered Methodology for Creating AI FactSheets. Bulletin of the IEEE Computer Society Technical Committee on Data Engineering. Available at http://sites.computer.org/debull/A21dec/p47.pdf

OECD (2022), "OECD Framework for the Classification of AI systems", OECD Digital Economy Papers, No. 323, OECD Publishing, Paris, https://doi.org/10.1787/cb6d9eca-en.

</details>
