---
date: 03-04-01
title: MANAGE 4.1
categories:
  - MANAGE-4
description: Post-deployment AI system monitoring plans are implemented, including mechanisms for capturing and evaluating input from users and other relevant AI actors, appeal and override, decommissioning, incident response, recovery, and change management.
type: Manage
order_number: 1
---
{::options parse_block_html="true" /} 


<details>
<summary markdown="span"><span style="color:#FBFAF5">**About**</span></summary>      
<br>
AI system performance and trustworthiness can change due to a variety of factors. Regular AI system monitoring can help deployers identify performance degradations, adversarial attacks, unexpected and unusual behavior, and impacts. Including pre- and post-deployment external feedback about AI system performance can enhance organizational awareness about positive and negative impacts, and reduce the time to respond to risks and harms. 

</details>

<details>
<summary markdown="span"><span style="color:#FBFAF5">**Suggested Actions**</span></summary>

- Establish and maintain procedures to monitor AI system performance for risks and negative and positive impacts associated with trustworthiness characteristics. 
- Perform post-deployment TEVV tasks to evaluate AI system validity and reliability, bias and fairness, privacy, and security and resilience.
- Evaluate AI system trustworthiness in conditions similar to deployment context of use, and prior to deployment.
- Establish and implement red-teaming exercises at a prescribed cadence, and evaluate their efficacy. 
- Establish procedures for tracking dataset modifications such as data deletion or rectification requests.
- Establish mechanisms for regular communication and feedback between relevant AI actors and internal or external stakeholders to capture information about system performance, trustworthiness and impact.
- Share information about errors and attack patterns with incident databases, other organizations with similar systems, and system users and stakeholders.
- Respond to and document detected or reported negative impacts or issues in AI system performance and trustworthiness.
- Decommission systems that exceed establish risk tolerances.

</details>

<details>
<summary markdown="span"><span style="color:#FBFAF5">**Transparency and Documentation**</span></summary>
<br>
**Organizations can document the following:**

- To what extent has the entity documented the post-deployment AI systemâ€™s testing methodology, metrics, and performance outcomes?
- How easily accessible and current is the information available to external stakeholders?

**AI Transparency Resources:**

- GAO-21-519SP - Artificial Intelligence: An Accountability Framework for Federal Agencies & Other Entities, [URL](https://www.gao.gov/products/gao-21-519sp)
- Datasheets for Datasets. [URL](https://arxiv.org/abs/1803.09010)

</details>

<details>
<summary markdown="span"><span style="color:#FBFAF5">**References**</span></summary>      
<br>
Navdeep Gill, Patrick Hall, Kim Montgomery, and Nicholas Schmidt. "A Responsible Machine Learning Workflow with Focus on Interpretable Models, Post-hoc Explanation, and Discrimination Testing." Information 11, no. 3 (2020): 137. [URL](https://www.mdpi.com/2078-2489/11/3/137)

</details>
