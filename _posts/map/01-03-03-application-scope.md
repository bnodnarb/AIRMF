---
date: 01-03-03
title: MAP 3.3
categories:
  - MAP-3
description: Targeted application scope is specified, narrowed, and documented based on established context and AI system classification.
type: Map
order_number: 3
---

{::options parse_block_html="true" /}


<details>
<summary markdown="span">**About**</summary>
<br>
Systems that function in a narrow scope tend to enable better mapping, measurement, and management of risks in the learning or decision-making tasks and the system context. A narrow application scope also helps ease oversight functions and related resources within an organization.

For example, open-ended chatbot systems that interact with the public on the internet have a large number of risks that may be difficult to map, measure, and manage due to the variability from both the decision-making task and the operational context. Instead, a task-specific chatbot that utilizes specific templated responses that follow a defined “user journey” is a scope that can be more easily mapped, measured and managed. 

</details>

<details>
<summary markdown="span">**Actions**</summary>

* Consider narrowing contexts for system deployment, including factors related to:
    * How outcomes may directly or indirectly impact users and stakeholders.
    * Length of time the system is deployed in between re-trainings. 
    * Geographical regions in which the system operates.
* Engage AI actors from legal and procurement functions when specifying target application scope.

</details>

<details>
<summary markdown="span">**Transparency and Documentation**</summary>
<br>
**Organizations can document the following:**
- To what extent has the entity clearly defined technical specifications and requirements for the AI system?
- How do the technical specifications and requirements align with the AI system’s goals and objectives?

**AI Transparency Resources:**
- GAO-21-519SP: AI Accountability Framework for Federal Agencies & Other Entities
- Assessment List for Trustworthy AI (ALTAI) - The High-Level Expert Group on AI – 2019

</details>

<details>
<summary markdown="span">**References**</summary>    
<br>
Mark J. Van der Laan and Sherri Rose (2018). Targeted Learning in Data Science. Cham: Springer International Publishing, 2018.

Alice Zheng. 2015. Evaluating Machine Learning Models (2015). O'Reilly. [URL](https://www.oreilly.com/library/view/evaluating-machine-learning/9781492048756/)

Brenda Leong and Patrick Hall (2021). 5 things lawyers should know about artificial intelligence. ABA Journal. [URL](https://www.abajournal.com/columns/article/5-things-lawyers-should-know-about-artificial-intelligence)

UK Centre for Data Ethics and Innovation, “The roadmap to an effective AI assurance ecosystem”. [URL](https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/1039146/The_roadmap_to_an_effective_AI_assurance_ecosystem.pdf)

</details>
