---
date: 04-01-02
title: GOVERN 1.3
categories:
  - GOVERN-1
description: The risk management process and its outcomes are established through transparent mechanisms and all significant risks are measured.
type: Govern
order_number: 3
---
{::options parse_block_html="true" /}


<details>
<summary markdown="span">**About**</summary>
<br>
Standardized documentation can operationalize how organizational AI risk management processes are implemented and recorded. Systematizing documentation can also enhance accountability efforts. By adding their contact information to a work product document, AI actors can improve communication, increase ownership of work products, and potentially enhance consideration of product quality. Documentation may generate downstream benefits related to improved system replicability and robustness. Proper documentation storage and access procedures allow for quick retrieval of critical information during a negative incident.

</details>

<details>
<summary markdown="span">**Actions**</summary>
<br>
Establish policies for identifying and monitoring AI system incidents related to trustworthy AI characteristics, or confirm that existing incident response policies address AI systems and their trustworthiness. Organizational policies may address the following:

Scope, approach, and definition setting:
- Establish AI risk management policies that broadly align to AI system trustworthy characteristics.
- Define key terms and concepts related to AI systems and the scope of their intended use.
- Address the use of sensitive or otherwise risky data.
- Outline and document risk mapping and measurement processes and standards.

Verification and validation for compliance requirements: 
- Verify that formal AI risk management policies align to existing legal standards, and industry best practices and norms.
- Verify that formal AI risk management policies include currently deployed and third-party AI systems

Process and standards modeling:
- Detail standards for experimental design, data quality, and model training.
- Detail model testing and validation processes.
- Detail and test incident response plans.


</details>

<details>
<summary markdown="span">**Transparency and Documentation**</summary>
<br>
**Organizations can document the following:**
- To what extent does the system/entity consistently measure progress towards stated goals and objectives?
- Did your organization implement a risk management system to address risks involved in deploying the identified AI solution (e.g. personnel risk or changes to commercial objectives)?
- Did your organization address usability problems and test whether user interfaces served their intended purposes? Consulting the community or end users at the earliest stages of development to ensure there is transparency on the technology used and how it is deployed.

**AI Transparency Resources:**
- [GAO-21-519SP: AI Accountability Framework for Federal Agencies & Other Entities](https://www.gao.gov/products/gao-21-519sp)
- [WEF Model AI Governance Framework Assessment 2020](https://www.pdpc.gov.sg/-/media/Files/PDPC/PDF-Files/Resource-for-Organisation/AI/SGModelAIGovFramework2.pdf)

</details>

<details>
<summary markdown="span">**References**</summary>
<br>
National Institute of Standards and Technology. (2018). Framework for improving critical infrastructure cybersecurity. [URL](https://nvlpubs.nist.gov/nistpubs/cswp/nist.cswp.04162018.pdf)

National Institute of Standards and Technology. (2012). Computer Security Incident Handling Guide. NIST Special Publication 800-61 Revision 2. [URL](https://nvlpubs.nist.gov/nistpubs/specialpublications/nist.sp.800-61r2.pdf)

</details>
